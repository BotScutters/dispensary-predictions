{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling Mary Jane\n",
    "==============\n",
    "\n",
    "***Using machine earning to reveal insights and predict performance of cannabis dispensaries***\n",
    "\n",
    "**Author:** *Scott Butters*\n",
    "\n",
    "\n",
    "\n",
    "# Abstract\n",
    "\n",
    "In 2012, Washington state passed I-502 and legalized the recreational sale, use, and possession of marijuana. Since 2014, approximately 500 state licensed dispensaries have opened throughout the state, with nearly 150 of those here in Seattle. The industry is heavily tracked and regulated and a wealth of sales and business statistics are publicly available. In this project I scour the web for publicly available data that might be predictive of how a cannabis dispensary performs, such as customer reviews, inventory distributions, and local demographics. I then train machine learning models to predict a dispensary's monthly revenue and analyze the resulting models to distill insights about what drives sales in the marijuana market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "The data for this project is derived from several sources:\n",
    "\n",
    "## Dispensary profiles from [Leafly](www.leafly.com)\n",
    "\n",
    "Leafly is an information aggregator for cannabis. They maintain a profile for most of the dispensaries in the state. As part of my dataset, I've scraped the following features from the Leafly website for each dispensary for which it was available:\n",
    "\n",
    "* Average customer rating and number of customer reviews\n",
    "* Inventory counts (number of products under descriptions like \"flower\", \"edibles\", \"concentrates\", etc.\n",
    "* Categorical qualities, such as whether or not the store is ADA accessible or has an ATM onsite\n",
    "* Metadata such as name, address, phone number, etc.\n",
    "\n",
    "The combination of these features gives us a profile of each dispensary that allow us to draw insights from our model into what makes for a successful dispensary.\n",
    "\n",
    "## Demographics from [WA HomeTownLocator](https://washington.hometownlocator.com/)\n",
    "\n",
    "Of course, having the best inventory, friendliest staff and prettiest building in the state doesn't amount to anything if a dispensary is in the middle of nowhere. This is where demographic data comes in. WA HomeTownLocator maintains a database of demographic statistics for nearly every zip code in the state of Washington. The data is produced by Esri Demographics, and updated 4 times per year using data from the federal census, IRS, USPS, as well as local data sources and more. From this website I scraped data likely to be predictive of a local market such as:\n",
    "\n",
    "* Population density\n",
    "* Diversity\n",
    "* Average income\n",
    "\n",
    "These data give our model an image of what a dispensary's customer base is like, allowing us to characterize what makes for a good location to establish a dispensary.\n",
    "\n",
    "## [Washington State Liquor and Cannabis Board (WSLCB)](https://lcb.wa.gov/)\n",
    "\n",
    "Lastly, all that data would get us nowhere if we didn't have any target data to train our models on. That's where the WSLCB comes in. The WSLCB maintains data on every dispensary in the state, including monthly reports of revenue (which is what our model is predicting). Their data is scattered across a couple of different outlets, but for this project I used spreadsheets downloadable from [this obsure page](https://lcb.wa.gov/records/frequently-requested-lists) to get sales data dating back to November 2017. Because the only identifying information in that spreadsheet is the license number of the dispensary, I also downloaded a spreadsheet listing metadata for every entity that has applied for a Marijuana license, which I then joined with the sales data in order to link it up with data scraped from other resources.\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "The code below contains a pipeline to visit each of our sources and scrape or download all of the desired data into a few files stored in the data/raw/ directory to be scrubbed and processed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/data/make_dataset.py\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Helper functions\n",
    "def parse_products(text):\n",
    "    '''\n",
    "    Parses string of products into dictionary of products with counts\n",
    "    Input: string of products as scraped from Leafly dispensary page\n",
    "    Output: dictionary of {product: count} relationships\n",
    "    '''\n",
    "    repl = ['(', ')']\n",
    "    for char in repl:\n",
    "        text = text.replace(char, '')\n",
    "    prod_list = text.split('\\n')\n",
    "    prod_list = [prod.strip().lower() for prod in prod_list]\n",
    "    prod_dict = {}\n",
    "    for i, element in enumerate(prod_list):\n",
    "        if element.isnumeric():\n",
    "            prod_dict[prod_list[i - 1]] = int(element)\n",
    "        elif 'difference' in element:\n",
    "            pass\n",
    "        else:\n",
    "            prod_dict[element.strip()] = 0\n",
    "    return prod_dict\n",
    "\n",
    "\n",
    "def scrape_disp(disp, driver, user_agent):\n",
    "    \"\"\"\n",
    "    Scrapes dispensary-specific page on leafly for additional data and adds it\n",
    "    to existing dictionary dataset\n",
    "    Input: dictionary containing metadata for a single dispensary\n",
    "    Output: dictionary with additional metadata for given dispensary\n",
    "    \"\"\"\n",
    "    url = 'https://www.leafly.com/dispensary-info/'\n",
    "    slug = disp['slug']\n",
    "    url += slug\n",
    "    \n",
    "    if 'OR' in disp['formattedShortLocation']:\n",
    "        return {}\n",
    "    \n",
    "    response  = requests.get(url, headers=user_agent)\n",
    "    if not response.ok:\n",
    "        print('Connection to {} failed'.format(disp['name']))\n",
    "        return {}\n",
    "    \n",
    "    # Open page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Confirm over 21\n",
    "    try:\n",
    "        yes_button = driver.find_element_by_xpath('//button[text()=\"Yes\"]')\n",
    "        yes_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Scrape categoricals\n",
    "    try:\n",
    "        cat_selector = driver.find_element_by_class_name('jsx-4153842418')\n",
    "        # cat_selector = driver.find_element_by_tag_name('ul')\n",
    "        items = cat_selector.find_elements_by_tag_name(\"li\")\n",
    "        categories = {item.text.lower(): True for item in items}\n",
    "        disp.update(categories)\n",
    "    except:\n",
    "        print('Failed to scrape categories for {}'.format(disp['name']))\n",
    "        pass\n",
    "\n",
    "    # Scrape products\n",
    "    try:\n",
    "        products = driver.find_elements_by_class_name('jsx-1433915045')\n",
    "        products_text = products[0].text\n",
    "        product_dict = parse_products(products_text)\n",
    "        disp.update(product_dict)\n",
    "    except:\n",
    "        print('Failed to scrape products for {}'.format(disp['name']))\n",
    "        pass\n",
    "    \n",
    "    print('Successfully scraped {}'.format(disp['name']))\n",
    "    return disp\n",
    "\n",
    "\n",
    "def scrape_leafly_disps(path, disp_data_filename, data):\n",
    "    \"\"\"\n",
    "    Gets JSON file of data on dispensaries from Leafly, either by loading\n",
    "    pre-existing file or by re-scraping Leafly\n",
    "    Input: path and filename for output file, index  of basic dispensary metadata\n",
    "    Output: Index formatted JSON with one dictionary for each found dispensary\n",
    "    \"\"\"\n",
    "#     filepath = '../data/raw/dispensary_data.json'\n",
    "    filepath = path + disp_data_filename\n",
    "    if os.path.isfile(filepath):\n",
    "        overwrite = input(\n",
    "            '''Dispensaries data dict already exists. Scrape data again? y/n\\n\n",
    "            Note: this could take several minutes.''')\n",
    "        if overwrite.lower() != 'y':\n",
    "            with open(filepath) as json_file:\n",
    "                data = json.load(json_file)\n",
    "            return data\n",
    "\n",
    "    print(\"Beginning scrape...\")\n",
    "    ua = UserAgent()\n",
    "    user_agent = {'User-agent': ua.random}\n",
    "    chromedriver = \"/Applications/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "    for disp in data:\n",
    "        new_data = scrape_disp(data[disp], driver, user_agent)\n",
    "        data[disp].update(new_data)\n",
    "    \n",
    "    with open(filepath, 'w') as outfile:  \n",
    "        json.dump(data, outfile)\n",
    "        print('Scraped data written to {}'.format(filepath))\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def retry(TL_lat, TL_lon, cell_size):\n",
    "    '''\n",
    "    If request hits Leafly API limit, split cell into 4 subcells and retry\n",
    "    Input: Lat/lon coordinates for top left of map and optionally a size for\n",
    "    the map area (defaults to 0.5)\n",
    "    Output: dictionary of dictionaries containing metadata for each dispensary \n",
    "    found in map area\n",
    "    '''\n",
    "    TL_lats = [TL_lat, TL_lat - 0.4 * cell_size]\n",
    "    TL_lons = [TL_lat, TL_lat + 0.4 * cell_size]\n",
    "    disp_data = {}\n",
    "    for lat, lon in zip(TR_lats, TR_lons):\n",
    "        data = get_disp_data_by_coords(lat, lon, cell_size=0.6 * cell_size)\n",
    "        disp_data.update(data)\n",
    "    return disp_data\n",
    "\n",
    "\n",
    "def get_disp_data_by_coords(TL_lat, TL_lon, cell_size=0.5):\n",
    "    \"\"\"\n",
    "    Performs search for all dispensaries within a map region on Leafly\n",
    "    Input: Lat/lon coordinates for top left of map and optionally a size for\n",
    "    the map area (defaults to 0.5)\n",
    "    Output: dictionary of dictionaries containing metadata for each dispensary \n",
    "    found in map area\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    BR_lat = TL_lat - cell_size\n",
    "    BR_lon = TL_lon + cell_size\n",
    "    coords = TL_lat, TL_lon, BR_lat, BR_lon\n",
    "    \n",
    "    url = (\n",
    "        'https://web-finder.leafly.com/api/searchThisArea?topLeftLat={}&topLeftLon={}&bottomRightLat={}&bottomRightLon={}&userLat=47.6&userLon=-122.3'\n",
    "        ).format(TL_lat, TL_lon, BR_lat, BR_lon)\n",
    "    \n",
    "    # Scrape\n",
    "    time.sleep(.5+2*random.random())\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        print('Leafly search failed at {}'.format(coords))\n",
    "        return {}\n",
    "    disps = r.json()\n",
    "    \n",
    "    # Parse\n",
    "    fields = ['name', 'address1', 'address2', 'city', 'location', 'phone',\n",
    "              'formattedShortLocation', 'medical', 'recreational', 'tier', \n",
    "              'lastMenuUpdate', 'starRating', 'numberOfReviews', 'slug']\n",
    "\n",
    "    disp_data = {\n",
    "        d['name']: {k: d[k] for k in fields} for d in disps['dispensaries']}\n",
    "    entries = len(disp_data)\n",
    "    \n",
    "    # Check results; retry if necessary and return data\n",
    "    if entries > 200:\n",
    "        return retry(TR_lat, TR_lon, cell_size)\n",
    "    elif entries < 1:\n",
    "#         print('no results at {}'.format(coords))\n",
    "        return {}\n",
    "    else:\n",
    "#         print('{} results found at {}'.format(len(disp_data), coords))\n",
    "        return disp_data\n",
    "    \n",
    "    \n",
    "def get_rect_disp_data(TL_lat, TL_lon, BR_lat, BR_lon, cell_size=0.5):\n",
    "    \"\"\"\n",
    "    Performs grid search on sub-rectangles with slight overlap, gathering data \n",
    "    on each cell\n",
    "    Input: lat/lon coords of top left and bottom right corners, as well as \n",
    "    optional cell size parameter (defaults to 0.5)\n",
    "    Output: dictionary of dictionaries representing all dispensaries in\n",
    "    rectangle\n",
    "    \"\"\"\n",
    "    coords = TL_lat, TL_lon, BR_lat, BR_lon\n",
    "    max_step = 0.8 * cell_size\n",
    "    lat_steps = np.ceil((TL_lat - BR_lat - cell_size) / max_step)\n",
    "    lon_steps = np.ceil((BR_lon - TL_lon - cell_size) / max_step)\n",
    "\n",
    "    TL_lats = np.linspace(TL_lat, BR_lat + cell_size, lat_steps + 1)\n",
    "    TL_lons = np.linspace(TL_lon, BR_lon - cell_size, lon_steps + 1)\n",
    "\n",
    "    disp_data = {}\n",
    "\n",
    "    for lat in TL_lats:\n",
    "        for lon in TL_lons:\n",
    "            data = get_disp_data_by_coords(lat, lon, cell_size)\n",
    "            disp_data.update(data)\n",
    "\n",
    "    print('Total dispensaries found: ', len(disp_data))\n",
    "    return disp_data\n",
    "\n",
    "\n",
    "def get_disp_dict(path):\n",
    "    \"\"\"\n",
    "    Performs a grid search across Washington for all dispensaries with an\n",
    "    account on Leafly and scrapes metadata for each\n",
    "    Input: relative path to raw data directory\n",
    "    Output: Index formatted JSON with one dictionary for each found dispensary\n",
    "    \"\"\"\n",
    "    filepath = path + 'dispensary_list.json'\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        overwrite = input(\n",
    "            '''Initial dispensary list already exists. Scrape data again? y/n\\n \n",
    "            Note: this could take several minutes.''')\n",
    "        if overwrite.lower() != 'y':\n",
    "            with open(filepath) as json_file:\n",
    "                data = json.load(json_file)\n",
    "            return data\n",
    "    print(\"Beginning scrape...\")\n",
    "    \n",
    "    # WA State bounding coordinates\n",
    "    north = 49\n",
    "    west = -124.8\n",
    "    south = 45.4\n",
    "    east = -116.8\n",
    "    \n",
    "    data = get_rect_disp_data(north, west, south, east, cell_size=1.4)\n",
    "    \n",
    "    with open(filepath, 'w') as outfile:  \n",
    "        json.dump(data, outfile)\n",
    "        print('Scraped data written to {}'.format(filepath))\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_leafly_disp_data(path, disp_filename):\n",
    "    \"\"\"\n",
    "    Steps through all helper functions to scrape data from Leafly\n",
    "    Input: raw data path and desired filename for output\n",
    "    Output: JSON file containing scraped data\n",
    "    \"\"\"\n",
    "    disp_dict = get_disp_dict(path)\n",
    "    disp_data = scrape_leafly_disps(path, disp_filename, disp_dict)\n",
    "    return\n",
    "\n",
    "\n",
    "def get_demo_data(path, license_filename, demo_filename):\n",
    "    \"\"\"\n",
    "    Scrapes zip code based demographic data from washington.hometownlocator.com\n",
    "    for all zip codes containing a dispensary found in WSLCB license data\n",
    "    Input: relative path to raw data directory, license data filename, \n",
    "    demographics data filename\n",
    "    Output: saves demographic dataset to csv in raw data directory\n",
    "    \"\"\"\n",
    "    license_filepath = path + license_filename\n",
    "    demo_filepath = path + demo_filename\n",
    "\n",
    "    if os.path.isfile(demo_filepath):\n",
    "        overwrite = input(\n",
    "            '''Demographics file already exists. Scrape data again? y/n\\n \n",
    "            Note: this could take several minutes.''')\n",
    "        if overwrite.lower() != 'y':\n",
    "            return\n",
    "    \n",
    "    license_data = pd.read_excel(license_filepath, sheet_name=2, header=0)\n",
    "    zips = license_data['ZipCode'].astype(str).str[:5].unique()\n",
    "    demographics = pd.DataFrame()\n",
    "    \n",
    "    print(\"Beginning scrape...\")\n",
    "    for zip_code in sorted(zips):\n",
    "        url = f'https://washington.hometownlocator.com/zip-codes/data,zipcode,{zip_code}.cfm'\n",
    "        r = requests.get(url)\n",
    "        if 'table' in r.text:\n",
    "            df0, df1 = pd.read_html(url, index_col=0)[:2]\n",
    "            df0.columns = [str(zip_code)]\n",
    "            df1.columns = [str(zip_code)]\n",
    "            df = pd.concat([df0, df1], axis=0).T.dropna(axis=1)\n",
    "            df.drop(['INCOME', 'HOUSEHOLDS'], axis=1, inplace=True)\n",
    "            demographics = pd.concat([demographics, df])\n",
    "            print('Scraped {}/{} zips. Latest: {}'\n",
    "                  .format(len(demographics), len(zips), zip_code), end='\\r')\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            print(f'\\nNo data found for {zip_code}')\n",
    "        \n",
    "    demographics.to_csv(demo_filepath)\n",
    "    print('Scraped data written to {}'.format(demo_filepath))\n",
    "    return\n",
    "    \n",
    "    \n",
    "def download_dataset(url, path, filename):\n",
    "    \"\"\"\n",
    "    Downloads dataset from specified url and saves file to raw data directory\n",
    "    Input: url from which to retrieve data, filename to store data in\n",
    "    Output: dataset stored in raw data file directory\n",
    "    \"\"\"\n",
    "#     filepath = '../data/raw/{}'.format(filename)\n",
    "    filepath = path + filename\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    if file_exists:\n",
    "        overwrite = input('{} already exists. Update? y/n'.format(filename))\n",
    "        if overwrite.lower() != 'y':\n",
    "            return\n",
    "    print(\"Beginning file download...\")\n",
    "    r = requests.get(url)\n",
    "    if not r.ok:\n",
    "        print('Download failed')\n",
    "        return\n",
    "    with open(filepath, 'wb') as f:  \n",
    "        f.write(r.content)\n",
    "    print('File written to {}\\n'.format(filepath))\n",
    "    return\n",
    "    \n",
    "    \n",
    "def get_sales_data(path, sales_filename, license_filename):\n",
    "    \"\"\"\n",
    "    Gets links for most up-to-date dispensary sales and license information\n",
    "    from WSLCB and downloads datasets\n",
    "    Input:\n",
    "    Output: downloaded files to raw data directory\n",
    "    \"\"\"\n",
    "    # Get urls for most up-to-date sales and license data\n",
    "    url = 'https://lcb.wa.gov/records/frequently-requested-lists'\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        links = soup.find_all('a')\n",
    "        for link in links:\n",
    "            if 'Traceability' in link.text:\n",
    "                sales_url = link['href']\n",
    "                print(f'\\nLatest sales data found:\\n{sales_url}')\n",
    "                #filename = 'sales_data.xlsx'\n",
    "                download_dataset(sales_url, path, sales_filename)\n",
    "            elif 'Applicants' in link.text:\n",
    "                licenses_url = link['href']\n",
    "                print(f'\\nLatest license data found:\\n{licenses_url}')\n",
    "                #filename = 'license_data.xls'\n",
    "                download_dataset(licenses_url, path, license_filename)\n",
    "    else:\n",
    "        print('Failed to download sales data')\n",
    "\n",
    "    return\n",
    "\n",
    "    \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that download data several\n",
    "    sources and saves those datasets to the data/raw directory.\n",
    "    \"\"\"\n",
    "    path = '../data/raw/'\n",
    "    \n",
    "    sales_filename = 'sales_data.xlsx'\n",
    "    license_filename = 'license_data.xls'\n",
    "    demo_filename = 'demographics.csv'\n",
    "    disp_filename = 'dispensary_data.json'\n",
    "    \n",
    "    get_sales_data(path, sales_filename, license_filename)\n",
    "    get_demo_data(path, license_filename, demo_filename)\n",
    "    get_leafly_disp_data(path, disp_filename)\n",
    "    \n",
    "    print('\\nData acquisition complete.\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latest license data found:\n",
      "https://lcb.wa.gov/sites/default/files/publications/Public_Records/2019/MarijuanaApplicants.xls\n",
      "license_data.xls already exists. Update? y/ny\n",
      "Beginning file download...\n",
      "File written to ../data/raw/license_data.xls\n",
      "\n",
      "Latest sales data found:\n",
      "https://lcb.wa.gov/sites/default/files/publications/Marijuana/sales_activity/2019-04-10-MJ-Sales-Activity-by-License-Number-Traceability-Contingency-Reporting.xlsx\n",
      "sales_data.xlsx already exists. Update? y/ny\n",
      "Beginning file download...\n",
      "File written to ../data/raw/sales_data.xlsx\n",
      "Demographics file already exists. Scrape data again? y/nn\n",
      "Initial dispensary list already exists. Scrape data again? y/nn\n",
      "Dispensaries data dict already exists. Scrape data again? y/nn\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "*Look through the raw data files and see what you will need to do to them in order to have a workable data set. If your source data is already well-formatted, you may want to ask yourself why it hasn't already been analyzed and what other people may have overlooked when they were working on it. Are there other data sources that might give you more insights on some of the data you have here?*\n",
    "\n",
    "*The end goal of this step is to produce a [design matrix](https://en.wikipedia.org/wiki/Design_matrix), containing one column for every variable that you are modeling, including a column for the outputs, and one row for every observation in your data set. It needs to be in a format that won't cause any problems as you visualize and model your data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/features/build_features.py\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def join_sales_data():\n",
    "    \"\"\"\n",
    "    Loads sales and license data files and joins them into one table\n",
    "    Also creates a column with zip code as a 5 digit string for later use\n",
    "    Input:\n",
    "    Output: returns merged dataframe\n",
    "    \"\"\"\n",
    "    path = '../data/raw/sales_data.xlsx'\n",
    "    disp_sales_data = pd.read_excel(path, sheet_name=0, header=3)\n",
    "    disp_sales_data.rename(columns={'License Number':'License #'}, inplace=True)\n",
    "    disp_sales_data.set_index(keys='License #', inplace=True)\n",
    "\n",
    "    path = '../data/raw/license_data.xls'\n",
    "    license_data = pd.read_excel(path, sheet_name=2, header=0, index_col=1)\n",
    "\n",
    "    sales_data = pd.merge(disp_sales_data, license_data, how='left', on='License #')\n",
    "    sales_data['zip_code'] = sales_data['ZipCode'].astype(str).str[:5]\n",
    "    \n",
    "    return sales_data\n",
    "\n",
    "\n",
    "def clean_leafly_data(path, filename):\n",
    "    \"\"\"\n",
    "    Loads and cleans raw data scraped from Leafly.\n",
    "    Input: dictionaries containing paths and filenames for input/output files\n",
    "    Output: a cleaned and pickled dataframe of data scraped from Leafly\n",
    "    \"\"\"\n",
    "    raw_filename = path['raw'] + filename['raw_leafly']\n",
    "    int_filename = path['interim'] + filename['int_leafly']\n",
    "    \n",
    "    leafly = pd.read_json(raw_filename)\n",
    "        \n",
    "    leafly.to_pickle(int_filename)\n",
    "    return\n",
    "\n",
    "    \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/raw, \n",
    "    cleans them, and converts the data into a design matrix that is ready\n",
    "    for modeling.\n",
    "    \"\"\"\n",
    "    path = {\n",
    "        'raw': '../data/raw/',\n",
    "        'interim': '../data/interim/',\n",
    "        'processed': '../data/processed/'\n",
    "    }\n",
    "    \n",
    "    filename = {\n",
    "        'raw_leafly': 'dispensary_data.json',\n",
    "        'raw_demo': 'demographics.csv',\n",
    "        'raw_license': 'license_data.xls',\n",
    "        'raw_sales': 'sales_data.xlsx',\n",
    "        'int_leafly': 'leafly.pkl',\n",
    "        'int_demo': 'demographics.pkl',\n",
    "        'int_sales': 'sales.pkl',\n",
    "        'processed': 'data.pkl'\n",
    "    }\n",
    "    \n",
    "    clean_leafly_data(path, filename)\n",
    "    clean_demographic_data(path, filename)\n",
    "    clean_wslcb_data(path, filename)\n",
    "    join_cleaned_data(path, filename)\n",
    "    build_features(path, filename)\n",
    "    \n",
    "    print('\\nData acquisition complete.\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 50)\n",
    "path = {\n",
    "    'raw': '../data/raw/',\n",
    "    'interim': '../data/interim/',\n",
    "    'processed': '../data/processed/'\n",
    "}\n",
    "    \n",
    "filename = {\n",
    "    'raw_leafly': 'dispensary_data.json',\n",
    "    'raw_demo': 'demographics.csv',\n",
    "    'raw_license': 'license_data.xls',\n",
    "    'raw_sales': 'sales_data.xlsx',\n",
    "    'int_leafly': 'leafly.pkl',\n",
    "    'int_demo': 'demographics.pkl',\n",
    "    'int_sales': 'sales.pkl',\n",
    "    'processed': 'data.pkl'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filename = path['raw'] + filename['raw_leafly']\n",
    "int_filename = path['interim'] + filename['int_leafly']\n",
    "\n",
    "data = pd.read_json(raw_filename, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 635 entries, Mister Buds to Canna4Life - Clarkston\n",
      "Data columns (total 30 columns):\n",
      "accessories               11 non-null float64\n",
      "ada accessible            289 non-null float64\n",
      "address1                  633 non-null object\n",
      "address2                  134 non-null object\n",
      "all products              255 non-null float64\n",
      "atm                       312 non-null float64\n",
      "cartridges                36 non-null float64\n",
      "city                      635 non-null object\n",
      "concentrates              238 non-null float64\n",
      "debit cards accepted      45 non-null float64\n",
      "edibles                   245 non-null float64\n",
      "flower                    248 non-null float64\n",
      "formattedShortLocation    635 non-null object\n",
      "lastMenuUpdate            624 non-null object\n",
      "location                  635 non-null object\n",
      "medical                   635 non-null int64\n",
      "name                      635 non-null object\n",
      "numberOfReviews           635 non-null int64\n",
      "other                     200 non-null float64\n",
      "phone                     624 non-null object\n",
      "pre-rolls                 245 non-null float64\n",
      "recreational              635 non-null int64\n",
      "seeds                     2 non-null float64\n",
      "slug                      635 non-null object\n",
      "starRating                635 non-null float64\n",
      "storefront                396 non-null float64\n",
      "tier                      635 non-null int64\n",
      "topicals                  37 non-null float64\n",
      "ufcw discount             8 non-null float64\n",
      "veteran discount          230 non-null float64\n",
      "dtypes: float64(17), int64(4), object(9)\n",
      "memory usage: 153.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['accessories', 'ada accessible', 'address1', 'address2', 'all products',\n",
       "       'atm', 'cartridges', 'city', 'concentrates', 'debit cards accepted',\n",
       "       'edibles', 'flower', 'formattedShortLocation', 'lastMenuUpdate',\n",
       "       'location', 'medical', 'name', 'numberOfReviews', 'other', 'phone',\n",
       "       'pre-rolls', 'recreational', 'seeds', 'slug', 'starRating',\n",
       "       'storefront', 'tier', 'topicals', 'ufcw discount', 'veteran discount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data.info())\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address1</th>\n",
       "      <th>address2</th>\n",
       "      <th>city</th>\n",
       "      <th>formattedShortLocation</th>\n",
       "      <th>location</th>\n",
       "      <th>lastMenuUpdate</th>\n",
       "      <th>phone</th>\n",
       "      <th>slug</th>\n",
       "      <th>tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mister Buds</th>\n",
       "      <td>Mister Buds</td>\n",
       "      <td>536 Marine Dr</td>\n",
       "      <td>None</td>\n",
       "      <td>Port Angeles</td>\n",
       "      <td>Port Angeles, WA</td>\n",
       "      <td>{'lat': 48.1219849, 'lon': -123.4437221}</td>\n",
       "      <td>2017-04-10T17:54:28.278868+00:00</td>\n",
       "      <td>(360) 797-1966</td>\n",
       "      <td>mister-buds</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origins Port Angeles</th>\n",
       "      <td>Origins Port Angeles</td>\n",
       "      <td>1215 E Front Street</td>\n",
       "      <td>None</td>\n",
       "      <td>Port Angeles</td>\n",
       "      <td>Port Angeles, WA</td>\n",
       "      <td>{'lat': 48.1115394, 'lon': -123.4118052}</td>\n",
       "      <td>2019-04-12T01:37:53.395365+00:00</td>\n",
       "      <td>360.406.4902</td>\n",
       "      <td>sparket-rnr</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis Coast</th>\n",
       "      <td>Cannabis Coast</td>\n",
       "      <td>193161 Highway 101</td>\n",
       "      <td>None</td>\n",
       "      <td>Forks</td>\n",
       "      <td>Forks, WA</td>\n",
       "      <td>{'lat': 47.9683179, 'lon': -124.404138}</td>\n",
       "      <td>2016-04-07T23:37:15.980746+00:00</td>\n",
       "      <td>(360) 374-4020</td>\n",
       "      <td>cannabis-coast</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lux Pot Shop - Ballard</th>\n",
       "      <td>Lux Pot Shop - Ballard</td>\n",
       "      <td>4912 17th Ave NW</td>\n",
       "      <td>None</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>{'lat': 47.6648419, 'lon': -122.3786413}</td>\n",
       "      <td>2019-04-12T00:37:20.749868+00:00</td>\n",
       "      <td>206-294-5586</td>\n",
       "      <td>stash-pot-shop</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature's Gifts - Sequim</th>\n",
       "      <td>Nature's Gifts - Sequim</td>\n",
       "      <td>755 W Washington St</td>\n",
       "      <td>Suite C</td>\n",
       "      <td>Sequim</td>\n",
       "      <td>Sequim, WA</td>\n",
       "      <td>{'lat': 48.0791305, 'lon': -123.1204523}</td>\n",
       "      <td>2019-04-12T03:17:37.187515+00:00</td>\n",
       "      <td>360-797-1993</td>\n",
       "      <td>natures-gifts-sequim</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name             address1  \\\n",
       "Mister Buds                          Mister Buds        536 Marine Dr   \n",
       "Origins Port Angeles        Origins Port Angeles  1215 E Front Street   \n",
       "Cannabis Coast                    Cannabis Coast   193161 Highway 101   \n",
       "Lux Pot Shop - Ballard    Lux Pot Shop - Ballard     4912 17th Ave NW   \n",
       "Nature's Gifts - Sequim  Nature's Gifts - Sequim  755 W Washington St   \n",
       "\n",
       "                        address2          city formattedShortLocation  \\\n",
       "Mister Buds                 None  Port Angeles       Port Angeles, WA   \n",
       "Origins Port Angeles        None  Port Angeles       Port Angeles, WA   \n",
       "Cannabis Coast              None         Forks              Forks, WA   \n",
       "Lux Pot Shop - Ballard      None       Seattle            Seattle, WA   \n",
       "Nature's Gifts - Sequim  Suite C        Sequim             Sequim, WA   \n",
       "\n",
       "                                                         location  \\\n",
       "Mister Buds              {'lat': 48.1219849, 'lon': -123.4437221}   \n",
       "Origins Port Angeles     {'lat': 48.1115394, 'lon': -123.4118052}   \n",
       "Cannabis Coast            {'lat': 47.9683179, 'lon': -124.404138}   \n",
       "Lux Pot Shop - Ballard   {'lat': 47.6648419, 'lon': -122.3786413}   \n",
       "Nature's Gifts - Sequim  {'lat': 48.0791305, 'lon': -123.1204523}   \n",
       "\n",
       "                                           lastMenuUpdate           phone  \\\n",
       "Mister Buds              2017-04-10T17:54:28.278868+00:00  (360) 797-1966   \n",
       "Origins Port Angeles     2019-04-12T01:37:53.395365+00:00    360.406.4902   \n",
       "Cannabis Coast           2016-04-07T23:37:15.980746+00:00  (360) 374-4020   \n",
       "Lux Pot Shop - Ballard   2019-04-12T00:37:20.749868+00:00    206-294-5586   \n",
       "Nature's Gifts - Sequim  2019-04-12T03:17:37.187515+00:00    360-797-1993   \n",
       "\n",
       "                                         slug  tier  \n",
       "Mister Buds                       mister-buds   900  \n",
       "Origins Port Angeles              sparket-rnr   300  \n",
       "Cannabis Coast                 cannabis-coast   900  \n",
       "Lux Pot Shop - Ballard         stash-pot-shop   200  \n",
       "Nature's Gifts - Sequim  natures-gifts-sequim   300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 635 entries, Mister Buds to Canna4Life - Clarkston\n",
      "Data columns (total 10 columns):\n",
      "name                      635 non-null object\n",
      "address1                  633 non-null object\n",
      "address2                  134 non-null object\n",
      "city                      635 non-null object\n",
      "formattedShortLocation    635 non-null object\n",
      "location                  635 non-null object\n",
      "lastMenuUpdate            624 non-null object\n",
      "phone                     624 non-null object\n",
      "slug                      635 non-null object\n",
      "tier                      635 non-null int64\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 54.6+ KB\n"
     ]
    }
   ],
   "source": [
    "meta_cols = ['name', 'address1', 'address2', 'city', 'formattedShortLocation', \n",
    "            'location', 'lastMenuUpdate', 'phone', 'slug', 'tier']\n",
    "metadata = data[meta_cols]\n",
    "display(metadata.head())\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada accessible</th>\n",
       "      <th>atm</th>\n",
       "      <th>debit cards accepted</th>\n",
       "      <th>medical</th>\n",
       "      <th>recreational</th>\n",
       "      <th>storefront</th>\n",
       "      <th>ufcw discount</th>\n",
       "      <th>veteran discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mister Buds</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origins Port Angeles</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis Coast</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lux Pot Shop - Ballard</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature's Gifts - Sequim</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ada accessible  atm debit cards accepted medical  \\\n",
       "Mister Buds                        NaN  NaN                  NaN       0   \n",
       "Origins Port Angeles               1.0  1.0                  NaN       0   \n",
       "Cannabis Coast                     NaN  1.0                  NaN       0   \n",
       "Lux Pot Shop - Ballard             1.0  1.0                  1.0       0   \n",
       "Nature's Gifts - Sequim            1.0  1.0                  NaN       0   \n",
       "\n",
       "                        recreational storefront ufcw discount veteran discount  \n",
       "Mister Buds                        1        1.0           NaN              NaN  \n",
       "Origins Port Angeles               1        1.0           NaN              1.0  \n",
       "Cannabis Coast                     1        1.0           NaN              NaN  \n",
       "Lux Pot Shop - Ballard             1        1.0           NaN              NaN  \n",
       "Nature's Gifts - Sequim            1        1.0           NaN              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 635 entries, Mister Buds to Canna4Life - Clarkston\n",
      "Data columns (total 8 columns):\n",
      "ada accessible          289 non-null category\n",
      "atm                     312 non-null category\n",
      "debit cards accepted    45 non-null category\n",
      "medical                 635 non-null category\n",
      "recreational            635 non-null category\n",
      "storefront              396 non-null category\n",
      "ufcw discount           8 non-null category\n",
      "veteran discount        230 non-null category\n",
      "dtypes: category(8)\n",
      "memory usage: 10.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['ada accessible', 'atm', 'debit cards accepted', 'medical', \n",
    "            'recreational', 'storefront', 'ufcw discount', 'veteran discount']\n",
    "categoricals = data[cat_cols].astype('category')\n",
    "display(categoricals.head())\n",
    "categoricals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessories</th>\n",
       "      <th>all products</th>\n",
       "      <th>cartridges</th>\n",
       "      <th>concentrates</th>\n",
       "      <th>edibles</th>\n",
       "      <th>flower</th>\n",
       "      <th>numberOfReviews</th>\n",
       "      <th>other</th>\n",
       "      <th>pre-rolls</th>\n",
       "      <th>seeds</th>\n",
       "      <th>starRating</th>\n",
       "      <th>topicals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mister Buds</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origins Port Angeles</th>\n",
       "      <td>NaN</td>\n",
       "      <td>621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>26</td>\n",
       "      <td>29.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.961538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis Coast</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lux Pot Shop - Ballard</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2849.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>634.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.358974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature's Gifts - Sequim</th>\n",
       "      <td>NaN</td>\n",
       "      <td>618.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.594737</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accessories  all products  cartridges  concentrates  \\\n",
       "Mister Buds                      NaN           NaN         NaN           NaN   \n",
       "Origins Port Angeles             NaN         621.0         NaN         176.0   \n",
       "Cannabis Coast                   NaN           NaN         NaN           NaN   \n",
       "Lux Pot Shop - Ballard           NaN        2849.0         NaN         634.0   \n",
       "Nature's Gifts - Sequim          NaN         618.0         NaN         262.0   \n",
       "\n",
       "                         edibles  flower  numberOfReviews  other  pre-rolls  \\\n",
       "Mister Buds                  NaN     NaN                3    NaN        NaN   \n",
       "Origins Port Angeles       175.0   115.0               26   29.0      126.0   \n",
       "Cannabis Coast               NaN     NaN                2    NaN        NaN   \n",
       "Lux Pot Shop - Ballard     765.0   659.0               52   49.0      742.0   \n",
       "Nature's Gifts - Sequim     73.0   153.0               19    NaN      130.0   \n",
       "\n",
       "                         seeds  starRating  topicals  \n",
       "Mister Buds                NaN    5.000000       NaN  \n",
       "Origins Port Angeles       NaN    4.961538       NaN  \n",
       "Cannabis Coast             NaN    5.000000       NaN  \n",
       "Lux Pot Shop - Ballard     NaN    4.358974       NaN  \n",
       "Nature's Gifts - Sequim    NaN    4.594737       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 635 entries, Mister Buds to Canna4Life - Clarkston\n",
      "Data columns (total 12 columns):\n",
      "accessories        11 non-null float64\n",
      "all products       255 non-null float64\n",
      "cartridges         36 non-null float64\n",
      "concentrates       238 non-null float64\n",
      "edibles            245 non-null float64\n",
      "flower             248 non-null float64\n",
      "numberOfReviews    635 non-null int64\n",
      "other              200 non-null float64\n",
      "pre-rolls          245 non-null float64\n",
      "seeds              2 non-null float64\n",
      "starRating         635 non-null float64\n",
      "topicals           37 non-null float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 64.5+ KB\n"
     ]
    }
   ],
   "source": [
    "num_cols = ['accessories', 'all products','cartridges', 'concentrates', \n",
    "            'edibles', 'flower', 'numberOfReviews', 'other', 'pre-rolls', \n",
    "            'seeds', 'starRating', 'topicals']\n",
    "numerical = data[num_cols]\n",
    "display(numerical.head())\n",
    "numerical.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessories</th>\n",
       "      <th>ada accessible</th>\n",
       "      <th>all products</th>\n",
       "      <th>atm</th>\n",
       "      <th>cartridges</th>\n",
       "      <th>concentrates</th>\n",
       "      <th>debit cards accepted</th>\n",
       "      <th>edibles</th>\n",
       "      <th>flower</th>\n",
       "      <th>medical</th>\n",
       "      <th>...</th>\n",
       "      <th>other</th>\n",
       "      <th>pre-rolls</th>\n",
       "      <th>recreational</th>\n",
       "      <th>seeds</th>\n",
       "      <th>starRating</th>\n",
       "      <th>storefront</th>\n",
       "      <th>tier</th>\n",
       "      <th>topicals</th>\n",
       "      <th>ufcw discount</th>\n",
       "      <th>veteran discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>289.0</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>312.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>396.0</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>653.207843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>173.084034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.771429</td>\n",
       "      <td>170.375000</td>\n",
       "      <td>0.415748</td>\n",
       "      <td>...</td>\n",
       "      <td>73.01500</td>\n",
       "      <td>119.734694</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.359332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>414.960630</td>\n",
       "      <td>20.054054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>93.586809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>516.822934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.279504</td>\n",
       "      <td>148.463357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.375333</td>\n",
       "      <td>145.833582</td>\n",
       "      <td>0.493239</td>\n",
       "      <td>...</td>\n",
       "      <td>167.71915</td>\n",
       "      <td>97.708662</td>\n",
       "      <td>0.215659</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.055869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.227442</td>\n",
       "      <td>20.771169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>337.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.75000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.404785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>146.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.656604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>229.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>215.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56.75000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>312.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3651.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>1031.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>949.000000</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1449.00000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accessories  ada accessible  all products    atm  cartridges  \\\n",
       "count    11.000000           289.0    255.000000  312.0   36.000000   \n",
       "mean     50.090909             1.0    653.207843    1.0  108.000000   \n",
       "std      93.586809             0.0    516.822934    0.0  119.279504   \n",
       "min       0.000000             1.0      1.000000    1.0    1.000000   \n",
       "25%       3.000000             1.0    337.500000    1.0   21.750000   \n",
       "50%       7.000000             1.0    534.000000    1.0   74.000000   \n",
       "75%      50.000000             1.0    820.000000    1.0  133.500000   \n",
       "max     312.000000             1.0   3651.000000    1.0  536.000000   \n",
       "\n",
       "       concentrates  debit cards accepted     edibles      flower     medical  \\\n",
       "count    238.000000                  45.0  245.000000  248.000000  635.000000   \n",
       "mean     173.084034                   1.0  138.771429  170.375000    0.415748   \n",
       "std      148.463357                   0.0  116.375333  145.833582    0.493239   \n",
       "min        2.000000                   1.0    0.000000    1.000000    0.000000   \n",
       "25%       74.000000                   1.0   66.000000   76.500000    0.000000   \n",
       "50%      146.000000                   1.0  109.000000  146.500000    0.000000   \n",
       "75%      229.500000                   1.0  185.000000  215.250000    1.000000   \n",
       "max     1031.000000                   1.0  949.000000  861.000000    1.000000   \n",
       "\n",
       "       ...       other   pre-rolls  recreational     seeds  starRating  \\\n",
       "count  ...   200.00000  245.000000    635.000000  2.000000  635.000000   \n",
       "mean   ...    73.01500  119.734694      0.951181  1.500000    4.359332   \n",
       "std    ...   167.71915   97.708662      0.215659  0.707107    1.055869   \n",
       "min    ...     0.00000    2.000000      0.000000  1.000000    0.000000   \n",
       "25%    ...    11.75000   60.000000      1.000000  1.250000    4.404785   \n",
       "50%    ...    24.50000   95.000000      1.000000  1.500000    4.656604   \n",
       "75%    ...    56.75000  154.000000      1.000000  1.750000    4.800000   \n",
       "max    ...  1449.00000  742.000000      1.000000  2.000000    5.000000   \n",
       "\n",
       "       storefront        tier    topicals  ufcw discount  veteran discount  \n",
       "count       396.0  635.000000   37.000000            8.0             230.0  \n",
       "mean          1.0  414.960630   20.054054            1.0               1.0  \n",
       "std           0.0  301.227442   20.771169            0.0               0.0  \n",
       "min           1.0    0.000000    0.000000            1.0               1.0  \n",
       "25%           1.0  200.000000    6.000000            1.0               1.0  \n",
       "50%           1.0  300.000000   14.000000            1.0               1.0  \n",
       "75%           1.0  900.000000   29.000000            1.0               1.0  \n",
       "max           1.0  900.000000  107.000000            1.0               1.0  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leafly.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from \n",
    "    data/processed, calculates descriptive statistics for the population,\n",
    "    and plots charts that visualize interesting relationships between \n",
    "    features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed')\n",
    "    # describe_features(data, 'reports/')\n",
    "    # generate_charts(data, 'reports/figures/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you learn? What relationships do you think will be most helpful as you build your model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "*Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from \n",
    "    data/processed, calculates descriptive statistics for the population,\n",
    "    and plots charts that visualize interesting relationships between \n",
    "    features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed/')\n",
    "    # train, test = train_test_split(data)\n",
    "    # save_train_test(train, test, 'data/processed/')\n",
    "    # model = build_model()\n",
    "    # model.fit(train)\n",
    "    # save_model(model, 'models/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from \n",
    "    data/processed, calculates descriptive statistics for the population,\n",
    "    and plots charts that visualize interesting relationships between\n",
    "    features.\n",
    "    \"\"\"\n",
    "    # test_X, test_y = load_test_data('data/processed')\n",
    "    # trained_model = load_model('models/')\n",
    "    # predictions = trained_model.predict(test_X)\n",
    "    # metrics = evaluate(test_y, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project2)",
   "language": "python",
   "name": "project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

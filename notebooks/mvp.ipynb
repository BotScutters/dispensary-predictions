{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling Mary Jane\n",
    "==============\n",
    "\n",
    "***Using machine earning to reveal insights and predict performance of cannabis dispensaries***\n",
    "\n",
    "**Author:** *Scott Butters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "In 2012, Washington state passed I-502 and legalized the recreational sale, use, and possession of marijuana. This event has led to an explosion of development in the field that's making waves through our society. Since 2014, approximately 500 state licensed dispensaries have opened throughout the state, with nearly 150 of those here in Seattle. And the thing that gets me excited is that because of regulations, a ton of their data is publicly available, meaning I got to play with it. We can go into the weeds later about how and why it took me a thousand websites and 4 different scraping techniques to get the data, and how my R^2 varied when I went shifted from 10-30 features to estimate the monthly revenue of a cannabis dispensary. But for now, let me tell you about what I learned as I immersed myself in this dataset over the past 2 weeks. In this project I scour the web for publicly available data that might be predictive of how a cannabis dispensary performs, such as customer reviews, inventory distributions, and local demographics. I then train machine learning models to predict a dispensary's monthly revenue and analyze the resulting models to distill insights about what drives sales in the marijuana market.\n",
    "\n",
    "\n",
    "In this project, I explored the question of what makes the Washington recreational cannabis market tick. I decided that if I could identify the features that most contributed to a dispensary's revenue, I could get a lot of insight out of how the features shake out. \n",
    "\n",
    "When asked what my project was, I kept saying that it was to use web scraping to predict monthly revenue using linear regression. And it was, of course it was. But that's not the point, that's not the story. \n",
    "\n",
    "Here's the monthly revenue of all dispensaries for the last 16 months. See the trend?\n",
    "\n",
    "Okay. Now. Here's the monthly revenue of a handful of dispensaries over that same period. See the trend?\n",
    "\n",
    "But we can show this better. Here's the average monthly change in revenue of a dispensary.\n",
    "Next to the change for the overall market. \n",
    "Next to variation in the S&P 500 over the same period.\n",
    "And now the top marijuana ETF out there.\n",
    "\n",
    "So if we're going to make choices about what to invest in to make a dispensary successful, we need to have the impacts of the external market in context. So I put those indicators in there for some regression models to see how significant a role they played.\n",
    "\n",
    "In at attempt to both have more data and isolate the time component of my analysis, I constructed a new target variable, which is marketshare. For each month, I divided the revenue of a given dispensary by the revenue of all of the dispensaries over that period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "The data for this project is derived from several sources:\n",
    "\n",
    "## Dispensary profiles from [Leafly](www.leafly.com)\n",
    "\n",
    "Leafly is an information aggregator for cannabis. They maintain a profile for most of the dispensaries in the state. As part of my dataset, I've scraped the following features from the Leafly website for each dispensary for which it was available:\n",
    "\n",
    "* Average customer rating and number of customer reviews\n",
    "* Inventory counts (number of products under descriptions like \"flower\", \"edibles\", \"concentrates\", etc.\n",
    "* Categorical qualities, such as whether or not the store is ADA accessible or has an ATM onsite\n",
    "* Metadata such as name, address, phone number, etc.\n",
    "\n",
    "The combination of these features gives us a profile of each dispensary that allow us to draw insights from our model into what makes for a successful dispensary.\n",
    "\n",
    "## Demographics from [WA HomeTownLocator](https://washington.hometownlocator.com/)\n",
    "\n",
    "Of course, having the best inventory, friendliest staff and prettiest building in the state doesn't amount to anything if a dispensary is in the middle of nowhere. This is where demographic data comes in. WA HomeTownLocator maintains a database of demographic statistics for nearly every zip code in the state of Washington. The data is produced by Esri Demographics, and updated 4 times per year using data from the federal census, IRS, USPS, as well as local data sources and more. From this website I scraped data likely to be predictive of a local market such as:\n",
    "\n",
    "* Population density\n",
    "* Diversity\n",
    "* Average income\n",
    "\n",
    "These data give our model an image of what a dispensary's customer base is like, allowing us to characterize what makes for a good location to establish a dispensary.\n",
    "\n",
    "## [Washington State Liquor and Cannabis Board (WSLCB)](https://lcb.wa.gov/)\n",
    "\n",
    "Lastly, all that data would get us nowhere if we didn't have any target data to train our models on. That's where the WSLCB comes in. The WSLCB maintains data on every dispensary in the state, including monthly reports of revenue (which is what our model is predicting). Their data is scattered across a couple of different outlets, but for this project I used spreadsheets downloadable from [this obsure page](https://lcb.wa.gov/records/frequently-requested-lists) to get sales data dating back to November 2017. Because the only identifying information in that spreadsheet is the license number of the dispensary, I also downloaded a spreadsheet listing metadata for every entity that has applied for a Marijuana license, which I then joined with the sales data in order to link it up with data scraped from other resources.\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "The code below contains a pipeline to visit each of our sources and scrape or download all of the desired data into a few files stored in the data/raw/ directory to be scrubbed and processed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/data/make_dataset.py\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Helper functions\n",
    "def parse_products(text):\n",
    "    '''\n",
    "    Parses string of products into dictionary of products with counts\n",
    "    Input: string of products as scraped from Leafly dispensary page\n",
    "    Output: dictionary of {product: count} relationships\n",
    "    '''\n",
    "    repl = ['(', ')']\n",
    "    for char in repl:\n",
    "        text = text.replace(char, '')\n",
    "    prod_list = text.split('\\n')\n",
    "    prod_list = [prod.strip().lower() for prod in prod_list]\n",
    "    prod_dict = {}\n",
    "    for i, element in enumerate(prod_list):\n",
    "        if element.isnumeric():\n",
    "            prod_dict[prod_list[i - 1]] = int(element)\n",
    "        elif 'difference' in element:\n",
    "            pass\n",
    "        else:\n",
    "            prod_dict[element.strip()] = 0\n",
    "    return prod_dict\n",
    "\n",
    "\n",
    "def scrape_disp(disp, driver, user_agent):\n",
    "    \"\"\"\n",
    "    Scrapes dispensary-specific page on leafly for additional data and adds it\n",
    "    to existing dictionary dataset\n",
    "    Input: dictionary containing metadata for a single dispensary\n",
    "    Output: dictionary with additional metadata for given dispensary\n",
    "    \"\"\"\n",
    "    url = 'https://www.leafly.com/dispensary-info/'\n",
    "    slug = disp['slug']\n",
    "    url += slug\n",
    "    \n",
    "    if 'OR' in disp['formattedShortLocation']:\n",
    "        return {}\n",
    "    \n",
    "    response  = requests.get(url, headers=user_agent)\n",
    "    if not response.ok:\n",
    "        print('Connection to {} failed'.format(disp['name']))\n",
    "        return {}\n",
    "    \n",
    "    # Open page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Confirm over 21\n",
    "    try:\n",
    "        yes_button = driver.find_element_by_xpath('//button[text()=\"Yes\"]')\n",
    "        yes_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Scrape categoricals\n",
    "    try:\n",
    "        cat_selector = driver.find_element_by_class_name('jsx-4153842418')\n",
    "        # cat_selector = driver.find_element_by_tag_name('ul')\n",
    "        items = cat_selector.find_elements_by_tag_name(\"li\")\n",
    "        categories = {item.text.lower(): True for item in items}\n",
    "        disp.update(categories)\n",
    "    except:\n",
    "        print('Failed to scrape categories for {}'.format(disp['name']))\n",
    "        pass\n",
    "\n",
    "    # Scrape products\n",
    "    try:\n",
    "        products = driver.find_elements_by_class_name('jsx-1433915045')\n",
    "        products_text = products[0].text\n",
    "        product_dict = parse_products(products_text)\n",
    "        disp.update(product_dict)\n",
    "    except:\n",
    "        print('Failed to scrape products for {}'.format(disp['name']))\n",
    "        pass\n",
    "    \n",
    "    print('Successfully scraped {}'.format(disp['name']))\n",
    "    return disp\n",
    "\n",
    "\n",
    "def scrape_leafly_disps(path, disp_data_filename, data):\n",
    "    \"\"\"\n",
    "    Gets JSON file of data on dispensaries from Leafly, either by loading\n",
    "    pre-existing file or by re-scraping Leafly\n",
    "    Input: path and filename for output file, index  of basic dispensary metadata\n",
    "    Output: Index formatted JSON with one dictionary for each found dispensary\n",
    "    \"\"\"\n",
    "#     filepath = '../data/raw/dispensary_data.json'\n",
    "    filepath = path + disp_data_filename\n",
    "    if os.path.isfile(filepath):\n",
    "        overwrite = input(\n",
    "            '''Dispensaries data dict already exists. Scrape data again? y/n\\n\n",
    "            Note: this could take several minutes.''')\n",
    "        if overwrite.lower() != 'y':\n",
    "            with open(filepath) as json_file:\n",
    "                data = json.load(json_file)\n",
    "            return data\n",
    "\n",
    "    print(\"Beginning scrape...\")\n",
    "    ua = UserAgent()\n",
    "    user_agent = {'User-agent': ua.random}\n",
    "    chromedriver = \"/Applications/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "    for disp in data:\n",
    "        new_data = scrape_disp(data[disp], driver, user_agent)\n",
    "        data[disp].update(new_data)\n",
    "    \n",
    "    with open(filepath, 'w') as outfile:  \n",
    "        json.dump(data, outfile)\n",
    "        print('Scraped data written to {}'.format(filepath))\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def retry(TL_lat, TL_lon, cell_size):\n",
    "    '''\n",
    "    If request hits Leafly API limit, split cell into 4 subcells and retry\n",
    "    Input: Lat/lon coordinates for top left of map and optionally a size for\n",
    "    the map area (defaults to 0.5)\n",
    "    Output: dictionary of dictionaries containing metadata for each dispensary \n",
    "    found in map area\n",
    "    '''\n",
    "    TL_lats = [TL_lat, TL_lat - 0.4 * cell_size]\n",
    "    TL_lons = [TL_lat, TL_lat + 0.4 * cell_size]\n",
    "    disp_data = {}\n",
    "    for lat, lon in zip(TR_lats, TR_lons):\n",
    "        data = get_disp_data_by_coords(lat, lon, cell_size=0.6 * cell_size)\n",
    "        disp_data.update(data)\n",
    "    return disp_data\n",
    "\n",
    "\n",
    "def get_disp_data_by_coords(TL_lat, TL_lon, cell_size=0.5):\n",
    "    \"\"\"\n",
    "    Performs search for all dispensaries within a map region on Leafly\n",
    "    Input: Lat/lon coordinates for top left of map and optionally a size for\n",
    "    the map area (defaults to 0.5)\n",
    "    Output: dictionary of dictionaries containing metadata for each dispensary \n",
    "    found in map area\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    BR_lat = TL_lat - cell_size\n",
    "    BR_lon = TL_lon + cell_size\n",
    "    coords = TL_lat, TL_lon, BR_lat, BR_lon\n",
    "    \n",
    "    url = (\n",
    "        'https://web-finder.leafly.com/api/searchThisArea?topLeftLat={}&topLeftLon={}&bottomRightLat={}&bottomRightLon={}&userLat=47.6&userLon=-122.3'\n",
    "        ).format(TL_lat, TL_lon, BR_lat, BR_lon)\n",
    "    \n",
    "    # Scrape\n",
    "    time.sleep(.5+2*random.random())\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        print('Leafly search failed at {}'.format(coords))\n",
    "        return {}\n",
    "    disps = r.json()\n",
    "    \n",
    "    # Parse\n",
    "    fields = ['name', 'address1', 'address2', 'city', 'location', 'phone',\n",
    "              'formattedShortLocation', 'medical', 'recreational', 'tier', \n",
    "              'lastMenuUpdate', 'starRating', 'numberOfReviews', 'slug']\n",
    "\n",
    "    disp_data = {\n",
    "        d['name']: {k: d[k] for k in fields} for d in disps['dispensaries']}\n",
    "    entries = len(disp_data)\n",
    "    \n",
    "    # Check results; retry if necessary and return data\n",
    "    if entries > 200:\n",
    "        return retry(TR_lat, TR_lon, cell_size)\n",
    "    elif entries < 1:\n",
    "#         print('no results at {}'.format(coords))\n",
    "        return {}\n",
    "    else:\n",
    "#         print('{} results found at {}'.format(len(disp_data), coords))\n",
    "        return disp_data\n",
    "    \n",
    "    \n",
    "def get_rect_disp_data(TL_lat, TL_lon, BR_lat, BR_lon, cell_size=0.5):\n",
    "    \"\"\"\n",
    "    Performs grid search on sub-rectangles with slight overlap, gathering data \n",
    "    on each cell\n",
    "    Input: lat/lon coords of top left and bottom right corners, as well as \n",
    "    optional cell size parameter (defaults to 0.5)\n",
    "    Output: dictionary of dictionaries representing all dispensaries in\n",
    "    rectangle\n",
    "    \"\"\"\n",
    "    coords = TL_lat, TL_lon, BR_lat, BR_lon\n",
    "    max_step = 0.8 * cell_size\n",
    "    lat_steps = np.ceil((TL_lat - BR_lat - cell_size) / max_step)\n",
    "    lon_steps = np.ceil((BR_lon - TL_lon - cell_size) / max_step)\n",
    "\n",
    "    TL_lats = np.linspace(TL_lat, BR_lat + cell_size, lat_steps + 1)\n",
    "    TL_lons = np.linspace(TL_lon, BR_lon - cell_size, lon_steps + 1)\n",
    "\n",
    "    disp_data = {}\n",
    "\n",
    "    for lat in TL_lats:\n",
    "        for lon in TL_lons:\n",
    "            data = get_disp_data_by_coords(lat, lon, cell_size)\n",
    "            disp_data.update(data)\n",
    "\n",
    "    print('Total dispensaries found: ', len(disp_data))\n",
    "    return disp_data\n",
    "\n",
    "\n",
    "def get_disp_dict(path):\n",
    "    \"\"\"\n",
    "    Performs a grid search across Washington for all dispensaries with an\n",
    "    account on Leafly and scrapes metadata for each\n",
    "    Input: relative path to raw data directory\n",
    "    Output: Index formatted JSON with one dictionary for each found dispensary\n",
    "    \"\"\"\n",
    "    filepath = path + 'dispensary_list.json'\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        overwrite = input(\n",
    "            '''Initial dispensary list already exists. Scrape data again? y/n\\n \n",
    "            Note: this could take several minutes.''')\n",
    "        if overwrite.lower() != 'y':\n",
    "            with open(filepath) as json_file:\n",
    "                data = json.load(json_file)\n",
    "            return data\n",
    "    print(\"Beginning scrape...\")\n",
    "    \n",
    "    # WA State bounding coordinates\n",
    "    north = 49\n",
    "    west = -124.8\n",
    "    south = 45.4\n",
    "    east = -116.8\n",
    "    \n",
    "    data = get_rect_disp_data(north, west, south, east, cell_size=1.4)\n",
    "    \n",
    "    with open(filepath, 'w') as outfile:  \n",
    "        json.dump(data, outfile)\n",
    "        print('Scraped data written to {}'.format(filepath))\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_leafly_disp_data(path, disp_filename):\n",
    "    \"\"\"\n",
    "    Steps through all helper functions to scrape data from Leafly\n",
    "    Input: raw data path and desired filename for output\n",
    "    Output: JSON file containing scraped data\n",
    "    \"\"\"\n",
    "    disp_dict = get_disp_dict(path)\n",
    "    disp_data = scrape_leafly_disps(path, disp_filename, disp_dict)\n",
    "    return\n",
    "\n",
    "\n",
    "def get_demo_data(path, license_filename, demo_filename):\n",
    "    \"\"\"\n",
    "    Scrapes zip code based demographic data from washington.hometownlocator.com\n",
    "    for all zip codes containing a dispensary found in WSLCB license data\n",
    "    Input: relative path to raw data directory, license data filename, \n",
    "    demographics data filename\n",
    "    Output: saves demographic dataset to csv in raw data directory\n",
    "    \"\"\"\n",
    "    license_filepath = path + license_filename\n",
    "    demo_filepath = path + demo_filename\n",
    "\n",
    "    if os.path.isfile(demo_filepath):\n",
    "        overwrite = input(\n",
    "            '''Demographics file already exists. Scrape data again? y/n\\n \n",
    "            Note: this could take several minutes.''')\n",
    "        if overwrite.lower() != 'y':\n",
    "            return\n",
    "    \n",
    "    license_data = pd.read_excel(license_filepath, sheet_name=2, header=0)\n",
    "    zips = license_data['ZipCode'].astype(str).str[:5].unique()\n",
    "    demographics = pd.DataFrame()\n",
    "    \n",
    "    print(\"Beginning scrape...\")\n",
    "    for zip_code in sorted(zips):\n",
    "        url = f'https://washington.hometownlocator.com/zip-codes/data,zipcode,{zip_code}.cfm'\n",
    "        r = requests.get(url)\n",
    "        if 'table' in r.text:\n",
    "            df0, df1 = pd.read_html(url, index_col=0)[:2]\n",
    "            df0.columns = [str(zip_code)]\n",
    "            df1.columns = [str(zip_code)]\n",
    "            df = pd.concat([df0, df1], axis=0).T.dropna(axis=1)\n",
    "            df.drop(['INCOME', 'HOUSEHOLDS'], axis=1, inplace=True)\n",
    "            demographics = pd.concat([demographics, df])\n",
    "            print('Scraped {}/{} zips. Latest: {}'\n",
    "                  .format(len(demographics), len(zips), zip_code), end='\\r')\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            print(f'\\nNo data found for {zip_code}')\n",
    "        \n",
    "    demographics.to_csv(demo_filepath)\n",
    "    print('Scraped data written to {}'.format(demo_filepath))\n",
    "    return\n",
    "    \n",
    "    \n",
    "def download_dataset(url, path, filename):\n",
    "    \"\"\"\n",
    "    Downloads dataset from specified url and saves file to raw data directory\n",
    "    Input: url from which to retrieve data, filename to store data in\n",
    "    Output: dataset stored in raw data file directory\n",
    "    \"\"\"\n",
    "#     filepath = '../data/raw/{}'.format(filename)\n",
    "    filepath = path + filename\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    if file_exists:\n",
    "        overwrite = input('{} already exists. Update? y/n'.format(filename))\n",
    "        if overwrite.lower() != 'y':\n",
    "            return\n",
    "    print(\"Beginning file download...\")\n",
    "    r = requests.get(url)\n",
    "    if not r.ok:\n",
    "        print('Download failed')\n",
    "        return\n",
    "    with open(filepath, 'wb') as f:  \n",
    "        f.write(r.content)\n",
    "    print('File written to {}\\n'.format(filepath))\n",
    "    return\n",
    "    \n",
    "    \n",
    "def get_sales_data(path, sales_filename, license_filename):\n",
    "    \"\"\"\n",
    "    Gets links for most up-to-date dispensary sales and license information\n",
    "    from WSLCB and downloads datasets\n",
    "    Input:\n",
    "    Output: downloaded files to raw data directory\n",
    "    \"\"\"\n",
    "    # Get urls for most up-to-date sales and license data\n",
    "    url = 'https://lcb.wa.gov/records/frequently-requested-lists'\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        links = soup.find_all('a')\n",
    "        for link in links:\n",
    "            if 'Traceability' in link.text:\n",
    "                sales_url = link['href']\n",
    "                print(f'\\nLatest sales data found:\\n{sales_url}')\n",
    "                #filename = 'sales_data.xlsx'\n",
    "                download_dataset(sales_url, path, sales_filename)\n",
    "            elif 'Applicants' in link.text:\n",
    "                licenses_url = link['href']\n",
    "                print(f'\\nLatest license data found:\\n{licenses_url}')\n",
    "                #filename = 'license_data.xls'\n",
    "                download_dataset(licenses_url, path, license_filename)\n",
    "    else:\n",
    "        print('Failed to download sales data')\n",
    "\n",
    "    return\n",
    "\n",
    "    \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that download data several\n",
    "    sources and saves those datasets to the data/raw directory.\n",
    "    \"\"\"\n",
    "    path = '../data/raw/'\n",
    "    \n",
    "    sales_filename = 'sales_data.xlsx'\n",
    "    license_filename = 'license_data.xls'\n",
    "    demo_filename = 'demographics.csv'\n",
    "    disp_filename = 'dispensary_data.json'\n",
    "    \n",
    "    get_sales_data(path, sales_filename, license_filename)\n",
    "    get_demo_data(path, license_filename, demo_filename)\n",
    "    get_leafly_disp_data(path, disp_filename)\n",
    "    \n",
    "    print('\\nData acquisition complete.\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latest license data found:\n",
      "https://lcb.wa.gov/sites/default/files/publications/Public_Records/2019/MarijuanaApplicants.xls\n",
      "license_data.xls already exists. Update? y/ny\n",
      "Beginning file download...\n",
      "File written to ../data/raw/license_data.xls\n",
      "\n",
      "Latest sales data found:\n",
      "https://lcb.wa.gov/sites/default/files/publications/Marijuana/sales_activity/2019-04-10-MJ-Sales-Activity-by-License-Number-Traceability-Contingency-Reporting.xlsx\n",
      "sales_data.xlsx already exists. Update? y/ny\n",
      "Beginning file download...\n",
      "File written to ../data/raw/sales_data.xlsx\n",
      "Demographics file already exists. Scrape data again? y/nn\n",
      "Initial dispensary list already exists. Scrape data again? y/nn\n",
      "Dispensaries data dict already exists. Scrape data again? y/nn\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "*Look through the raw data files and see what you will need to do to them in order to have a workable data set. If your source data is already well-formatted, you may want to ask yourself why it hasn't already been analyzed and what other people may have overlooked when they were working on it. Are there other data sources that might give you more insights on some of the data you have here?*\n",
    "\n",
    "*The end goal of this step is to produce a [design matrix](https://en.wikipedia.org/wiki/Design_matrix), containing one column for every variable that you are modeling, including a column for the outputs, and one row for every observation in your data set. It needs to be in a format that won't cause any problems as you visualize and model your data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/features/build_features.py\n",
    "# !pip install fuzzywuzzy\n",
    "# !pip install python-Levenshtein\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def build_features(path, filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    inpath = path['interim'] + filename['int_joined']\n",
    "    outpath = path['processed'] + filename['processed']\n",
    "    data = pd.read_pickle(inpath)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data.to_pickle(outpath)\n",
    "    return\n",
    "\n",
    "    \n",
    "def make_key(row, fields):\n",
    "    \"\"\"\n",
    "    Constructs a key from a simplified composite of a dispensary's name, city,\n",
    "    and address\n",
    "    Input: dataframe row (from apply function) along with a list of names of \n",
    "    fields to get key information from\n",
    "    Output: lowercase string containing unique tokens from each of the fields \n",
    "    with punctuation removed and commonly shortened terms abbreviated\n",
    "    \"\"\"\n",
    "    joined = ' '.join([row[str(f)] for f in fields if isinstance(f, str)]).lower()\n",
    "    remove = list('!@#$%^&*()-_+,./<>?[]{}')\n",
    "    for char in remove:\n",
    "        joined = joined.replace(char, '')\n",
    "    \n",
    "    abbr = {'street': 'st',\n",
    "            'road': 'rd',\n",
    "            'way': 'wy',\n",
    "            'drive': 'dr',\n",
    "            'highway': 'hwy',\n",
    "            'avenue': 'ave',\n",
    "            'boulevard': 'blvd',\n",
    "            'suite': 'ste',\n",
    "            'lane': 'ln',\n",
    "            'north': 'n',\n",
    "            'east': 'e',\n",
    "            'south': 's',\n",
    "            'west': 'w',\n",
    "            'northeast': 'ne',\n",
    "            'southeast': 'se',\n",
    "            'southwest': 'sw',\n",
    "            'northwest': 'nw',\n",
    "           }\n",
    "    \n",
    "    for token in abbr:\n",
    "        joined = joined.replace(token, abbr[token])\n",
    "    key = ' '.join(sorted(list(set(joined.split()))))\n",
    "    return key\n",
    "\n",
    "\n",
    "def join_cleaned_data(path, filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    names = ['int_leafly', 'int_sales', 'int_demo']\n",
    "    filepaths = [path['interim'] + filename[n] for n in names]\n",
    "    leafly, sales, demo = [pd.read_pickle(f) for f in filepaths]\n",
    "    \n",
    "    # Construct composite key for joining with sales data\n",
    "    key_fields = ['name', 'city', 'address1']\n",
    "    leafly['key'] = leafly.apply(make_key, axis=1, fields=key_fields)\n",
    "    sales['key'] = sales.apply(make_key, axis=1, fields=key_fields)\n",
    "    \n",
    "    ## merge leafly data into sales data\n",
    "    data = pd.merge(sales, leafly, how='left', on='key')\n",
    "\n",
    "    ## merge demo data into sales data\n",
    "    data = pd.merge(data, demo, how='left', on='zip_code')\n",
    "    \n",
    "    outpath = path['interim'] + filename['int_joined']\n",
    "    recent_sales.to_pickle(outpath)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sales_data(path, filename):\n",
    "    \"\"\"\n",
    "    Loads sales and license data files and joins them into one table\n",
    "    Also creates a column with zip code as a 5 digit string for later use\n",
    "    Input:\n",
    "    Output: returns merged dataframe\n",
    "    \"\"\"\n",
    "    filepath = path['raw'] + filename['raw_sales']\n",
    "    sales_data = pd.read_excel(filepath, sheet_name=0, header=3)\n",
    "    sales_data.rename(columns={'License Number':'License #'}, inplace=True)\n",
    "    sales_data.set_index(keys='License #', inplace=True)\n",
    "\n",
    "    filepath = path['raw'] + filename['raw_license']\n",
    "    license_data = pd.read_excel(filepath, sheet_name=2, header=0, index_col=1)\n",
    "\n",
    "    data = pd.merge(sales_data, license_data, how='left', on='License #')\n",
    "    \n",
    "    return data  \n",
    "\n",
    "    \n",
    "def clean_wslcb_data(path, filename):\n",
    "    \"\"\"\n",
    "    Loads, cleans, and joins raw license and sales data from WSLCB.\n",
    "    Input: dictionaries containing paths and filenames for input/output files\n",
    "    Output: a cleaned and pickled dataframe of data from WSLCB\n",
    "    \"\"\"\n",
    "    data = join_sales_data(path, filename)\n",
    "    data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "    data.rename(columns={\n",
    "        'tradename': 'name', \n",
    "        'dateissued': 'date_issued',\n",
    "        'dayphone': 'phone',\n",
    "        'street_address': 'address1'\n",
    "    }, inplace=True)\n",
    "\n",
    "    data['zip_code'] = data['zipcode'].astype(str).str[:5]\n",
    "    data['phone'] = data['phone'].astype(str).str[:-2]\n",
    "    data['name'] = data['name'].str.strip().str.lower()\n",
    "\n",
    "    data['reporting_period'] += '-01'\n",
    "    date_cols = ['reporting_period', 'date_issued']\n",
    "    for col in date_cols:\n",
    "        data[col] = pd.to_datetime(data[col], errors='coerce', yearfirst=True,\n",
    "                                   infer_datetime_format=True)\n",
    "\n",
    "    # Only working with most recent reporting period for now. Will have to\n",
    "    # refactor this portion if past observations are integrated into the model\n",
    "    recent = data['reporting_period'] == data['reporting_period'].max()\n",
    "    data = data[recent]\n",
    "\n",
    "    # Drop old columns we don't want anymore\n",
    "    cols = ['ubi', 'suite/rm', 'zipcode']\n",
    "    data.drop(columns=cols, inplace=True)\n",
    "    \n",
    "    # Drop rows without names\n",
    "    data.dropna(subset=['name'], inplace=True)\n",
    "    \n",
    "    outpath = path['interim'] + filename['int_sales']\n",
    "    data.to_pickle(outpath)\n",
    "    \n",
    "    print('\\nCleaned wslcb data:')\n",
    "    display(data.head())\n",
    "    return\n",
    "\n",
    "    \n",
    "def clean_demographic_data(path, filename):\n",
    "    \"\"\"\n",
    "    Loads and cleans raw demographic data.\n",
    "    Input: dictionaries containing paths and filenames for input/output files\n",
    "    Output: a cleaned and pickled dataframe of demographic\n",
    "    \"\"\"\n",
    "    raw_filename = path['raw'] + filename['raw_demo']\n",
    "    int_filename = path['interim'] + filename['int_demo']\n",
    "\n",
    "    data = pd.read_csv(raw_filename)\n",
    "\n",
    "    # Reformat column\n",
    "    data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "    data.rename(columns={\n",
    "        'unnamed:_0': 'zip_code', \n",
    "        'population_density2': 'population_density',\n",
    "        'diversity_index3': 'diversity_index',\n",
    "        'owner_occupied_hu': 'owner_occupied_housing_units',\n",
    "        'renter_occupied_hu': 'renter_occupied_housing_units'\n",
    "    }, inplace=True)\n",
    "    data.set_index('zip_code', drop=True, inplace=True)\n",
    "\n",
    "    # Reformat columns with dollar strings into ints\n",
    "    cols = ['median_household_income', 'average_household_income',\n",
    "            'per_capita_income', 'median_home_value', 'average_home_value']\n",
    "    for c in cols:\n",
    "        data[c] = data[c].str.replace('$', '').str.replace(',', '').astype(int)\n",
    "\n",
    "    # Split columns with number and percent values into separate columns\n",
    "    cols = ['total_housing_units', 'owner_occupied_housing_units', \n",
    "            'renter_occupied_housing_units', 'vacant_housing_units']\n",
    "    new_cols = {col:[f'{col}_#', f'{col}_%'] for col in cols}\n",
    "    for old, new in new_cols.items():\n",
    "        for char in list(',(%)'):\n",
    "            data[old] = data[old].str.replace(char, '')\n",
    "        data[new] = data[old].str.split().apply(pd.Series).astype(float)\n",
    "\n",
    "    # Drop old columns we don't want anymore\n",
    "    cols = ['total_housing_units', 'owner_occupied_housing_units', \n",
    "            'renter_occupied_housing_units', 'vacant_housing_units']\n",
    "    data.drop(columns=cols, inplace=True)\n",
    "    \n",
    "    data.to_pickle(int_filename)\n",
    "    \n",
    "    print('\\nCleaned demographic data:')\n",
    "    display(data.head())\n",
    "    return\n",
    "\n",
    "\n",
    "def clean_leafly_data(path, filename):\n",
    "    \"\"\"\n",
    "    Loads and cleans raw data scraped from Leafly.\n",
    "    Input: dictionaries containing paths and filenames for input/output files\n",
    "    Output: a cleaned and pickled dataframe of data scraped from Leafly\n",
    "    \"\"\"\n",
    "    raw_filename = path['raw'] + filename['raw_leafly']\n",
    "    int_filename = path['interim'] + filename['int_leafly']\n",
    "\n",
    "    # Read data from file to dataframe\n",
    "    data = pd.read_json(raw_filename, orient='index')\n",
    "\n",
    "    # Rename columns\n",
    "    data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "    data.rename(columns={\n",
    "        'formattedshortlocation': 'formatted_short_location', \n",
    "        'lastmenuupdate': 'last_menu_update',\n",
    "        'numberofreviews': 'number_of_reviews',\n",
    "        'pre-rolls': 'prerolls',\n",
    "        'starrating': 'star_rating'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Filter to only Washington entries\n",
    "    f = data['formatted_short_location'].str.contains('WA')\n",
    "    data = data[f]\n",
    "\n",
    "    # Cast menu update as datetime\n",
    "    data['last_menu_update'] = pd.to_datetime(\n",
    "        data['last_menu_update'], errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "    # Cast categorical features as such\n",
    "    cat_cols = ['ada_accessible', 'atm', 'debit_cards_accepted', 'medical', \n",
    "                'recreational', 'storefront', 'ufcw_discount', \n",
    "                'veteran_discount']\n",
    "    data[cat_cols] = data[cat_cols].astype('category')\n",
    "\n",
    "    \n",
    "    # Extact lat/lon coordinates into their own feature\n",
    "    data[['latitude', 'longitude']] = data['location'].apply(pd.Series)\n",
    "    \n",
    "    # Drop old columns we don't want anymore\n",
    "    cols = ['address2', 'formatted_short_location', 'location', 'phone', 'tier']\n",
    "    data.drop(columns=cols, inplace=True)\n",
    "    \n",
    "    # Pickle and return dataframe\n",
    "    data.to_pickle(int_filename)\n",
    "    \n",
    "    print('\\nCleaned Leafly data:')\n",
    "    display(data.head())\n",
    "    return data\n",
    "\n",
    "    \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/raw, \n",
    "    cleans them, and converts the data into a design matrix that is ready\n",
    "    for modeling.\n",
    "    \"\"\"\n",
    "    path = {\n",
    "        'raw': '../data/raw/',\n",
    "        'interim': '../data/interim/',\n",
    "        'processed': '../data/processed/'\n",
    "    }\n",
    "    \n",
    "    filename = {\n",
    "        'raw_leafly': 'dispensary_data.json',\n",
    "        'raw_demo': 'demographics.csv',\n",
    "        'raw_license': 'license_data.xls',\n",
    "        'raw_sales': 'sales_data.xlsx',\n",
    "        'int_leafly': 'leafly.pkl',\n",
    "        'int_demo': 'demographics.pkl',\n",
    "        'int_sales': 'sales.pkl',\n",
    "        'int_joined': 'joined_data.pkl',\n",
    "        'processed': 'data.pkl'\n",
    "    }\n",
    "    \n",
    "    clean_leafly_data(path, filename)\n",
    "    clean_demographic_data(path, filename)\n",
    "    clean_wslcb_data(path, filename)\n",
    "    join_cleaned_data(path, filename)\n",
    "    build_features(path, filename)\n",
    "    \n",
    "    print('\\nData acquisition complete.\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Leafly data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessories</th>\n",
       "      <th>ada_accessible</th>\n",
       "      <th>address1</th>\n",
       "      <th>all_products</th>\n",
       "      <th>atm</th>\n",
       "      <th>cartridges</th>\n",
       "      <th>city</th>\n",
       "      <th>concentrates</th>\n",
       "      <th>debit_cards_accepted</th>\n",
       "      <th>edibles</th>\n",
       "      <th>flower</th>\n",
       "      <th>last_menu_update</th>\n",
       "      <th>medical</th>\n",
       "      <th>name</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>other</th>\n",
       "      <th>prerolls</th>\n",
       "      <th>recreational</th>\n",
       "      <th>seeds</th>\n",
       "      <th>slug</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>storefront</th>\n",
       "      <th>topicals</th>\n",
       "      <th>ufcw_discount</th>\n",
       "      <th>veteran_discount</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mister Buds</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536 Marine Dr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-10 17:54:28.278868+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Mister Buds</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mister-buds</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.121985</td>\n",
       "      <td>-123.443722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origins Port Angeles</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1215 E Front Street</td>\n",
       "      <td>621.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port Angeles</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2019-04-12 01:37:53.395365+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Origins Port Angeles</td>\n",
       "      <td>26</td>\n",
       "      <td>29.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparket-rnr</td>\n",
       "      <td>4.961538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.111539</td>\n",
       "      <td>-123.411805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis Coast</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193161 Highway 101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-07 23:37:15.980746+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Cannabis Coast</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cannabis-coast</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.968318</td>\n",
       "      <td>-124.404138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lux Pot Shop - Ballard</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4912 17th Ave NW</td>\n",
       "      <td>2849.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>2019-04-12 00:37:20.749868+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Lux Pot Shop - Ballard</td>\n",
       "      <td>52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stash-pot-shop</td>\n",
       "      <td>4.358974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.664842</td>\n",
       "      <td>-122.378641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature's Gifts - Sequim</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>755 W Washington St</td>\n",
       "      <td>618.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sequim</td>\n",
       "      <td>262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2019-04-12 03:17:37.187515+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Nature's Gifts - Sequim</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>natures-gifts-sequim</td>\n",
       "      <td>4.594737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.079130</td>\n",
       "      <td>-123.120452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accessories ada_accessible             address1  \\\n",
       "Mister Buds                      NaN            NaN        536 Marine Dr   \n",
       "Origins Port Angeles             NaN            1.0  1215 E Front Street   \n",
       "Cannabis Coast                   NaN            NaN   193161 Highway 101   \n",
       "Lux Pot Shop - Ballard           NaN            1.0     4912 17th Ave NW   \n",
       "Nature's Gifts - Sequim          NaN            1.0  755 W Washington St   \n",
       "\n",
       "                         all_products  atm  cartridges          city  \\\n",
       "Mister Buds                       NaN  NaN         NaN  Port Angeles   \n",
       "Origins Port Angeles            621.0  1.0         NaN  Port Angeles   \n",
       "Cannabis Coast                    NaN  1.0         NaN         Forks   \n",
       "Lux Pot Shop - Ballard         2849.0  1.0         NaN       Seattle   \n",
       "Nature's Gifts - Sequim         618.0  1.0         NaN        Sequim   \n",
       "\n",
       "                         concentrates debit_cards_accepted  edibles  flower  \\\n",
       "Mister Buds                       NaN                  NaN      NaN     NaN   \n",
       "Origins Port Angeles            176.0                  NaN    175.0   115.0   \n",
       "Cannabis Coast                    NaN                  NaN      NaN     NaN   \n",
       "Lux Pot Shop - Ballard          634.0                  1.0    765.0   659.0   \n",
       "Nature's Gifts - Sequim         262.0                  NaN     73.0   153.0   \n",
       "\n",
       "                                        last_menu_update medical  \\\n",
       "Mister Buds             2017-04-10 17:54:28.278868+00:00       0   \n",
       "Origins Port Angeles    2019-04-12 01:37:53.395365+00:00       0   \n",
       "Cannabis Coast          2016-04-07 23:37:15.980746+00:00       0   \n",
       "Lux Pot Shop - Ballard  2019-04-12 00:37:20.749868+00:00       0   \n",
       "Nature's Gifts - Sequim 2019-04-12 03:17:37.187515+00:00       0   \n",
       "\n",
       "                                            name  number_of_reviews  other  \\\n",
       "Mister Buds                          Mister Buds                  3    NaN   \n",
       "Origins Port Angeles        Origins Port Angeles                 26   29.0   \n",
       "Cannabis Coast                    Cannabis Coast                  2    NaN   \n",
       "Lux Pot Shop - Ballard    Lux Pot Shop - Ballard                 52   49.0   \n",
       "Nature's Gifts - Sequim  Nature's Gifts - Sequim                 19    NaN   \n",
       "\n",
       "                         prerolls recreational  seeds                  slug  \\\n",
       "Mister Buds                   NaN            1    NaN           mister-buds   \n",
       "Origins Port Angeles        126.0            1    NaN           sparket-rnr   \n",
       "Cannabis Coast                NaN            1    NaN        cannabis-coast   \n",
       "Lux Pot Shop - Ballard      742.0            1    NaN        stash-pot-shop   \n",
       "Nature's Gifts - Sequim     130.0            1    NaN  natures-gifts-sequim   \n",
       "\n",
       "                         star_rating storefront  topicals ufcw_discount  \\\n",
       "Mister Buds                 5.000000        1.0       NaN           NaN   \n",
       "Origins Port Angeles        4.961538        1.0       NaN           NaN   \n",
       "Cannabis Coast              5.000000        1.0       NaN           NaN   \n",
       "Lux Pot Shop - Ballard      4.358974        1.0       NaN           NaN   \n",
       "Nature's Gifts - Sequim     4.594737        1.0       NaN           NaN   \n",
       "\n",
       "                        veteran_discount   latitude   longitude  \n",
       "Mister Buds                          NaN  48.121985 -123.443722  \n",
       "Origins Port Angeles                 1.0  48.111539 -123.411805  \n",
       "Cannabis Coast                       NaN  47.968318 -124.404138  \n",
       "Lux Pot Shop - Ballard               NaN  47.664842 -122.378641  \n",
       "Nature's Gifts - Sequim              1.0  48.079130 -123.120452  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned demographic data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_population</th>\n",
       "      <th>population_in_households</th>\n",
       "      <th>population_in_familes</th>\n",
       "      <th>population_in_group_qrtrs</th>\n",
       "      <th>population_density</th>\n",
       "      <th>diversity_index</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>average_household_income</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>median_home_value</th>\n",
       "      <th>average_home_value</th>\n",
       "      <th>total_households</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>family_households</th>\n",
       "      <th>average_family_size</th>\n",
       "      <th>total_housing_units_#</th>\n",
       "      <th>total_housing_units_%</th>\n",
       "      <th>owner_occupied_housing_units_#</th>\n",
       "      <th>owner_occupied_housing_units_%</th>\n",
       "      <th>renter_occupied_housing_units_#</th>\n",
       "      <th>renter_occupied_housing_units_%</th>\n",
       "      <th>vacant_housing_units_#</th>\n",
       "      <th>vacant_housing_units_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98002</th>\n",
       "      <td>35047</td>\n",
       "      <td>34605</td>\n",
       "      <td>26256</td>\n",
       "      <td>442</td>\n",
       "      <td>4906</td>\n",
       "      <td>70</td>\n",
       "      <td>47844</td>\n",
       "      <td>61905</td>\n",
       "      <td>24440</td>\n",
       "      <td>194413</td>\n",
       "      <td>208432</td>\n",
       "      <td>13599</td>\n",
       "      <td>2.54</td>\n",
       "      <td>8167</td>\n",
       "      <td>3</td>\n",
       "      <td>14495.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6511.0</td>\n",
       "      <td>44.9</td>\n",
       "      <td>7088.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>896.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98003</th>\n",
       "      <td>49533</td>\n",
       "      <td>48929</td>\n",
       "      <td>38209</td>\n",
       "      <td>604</td>\n",
       "      <td>4238</td>\n",
       "      <td>80</td>\n",
       "      <td>57052</td>\n",
       "      <td>76301</td>\n",
       "      <td>29554</td>\n",
       "      <td>278121</td>\n",
       "      <td>316089</td>\n",
       "      <td>18915</td>\n",
       "      <td>2.59</td>\n",
       "      <td>11705</td>\n",
       "      <td>3</td>\n",
       "      <td>19978.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>46.7</td>\n",
       "      <td>9595.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98004</th>\n",
       "      <td>35086</td>\n",
       "      <td>34949</td>\n",
       "      <td>24385</td>\n",
       "      <td>137</td>\n",
       "      <td>4799</td>\n",
       "      <td>56</td>\n",
       "      <td>107731</td>\n",
       "      <td>158537</td>\n",
       "      <td>76582</td>\n",
       "      <td>1000431</td>\n",
       "      <td>1150686</td>\n",
       "      <td>16921</td>\n",
       "      <td>2.07</td>\n",
       "      <td>8508</td>\n",
       "      <td>3</td>\n",
       "      <td>20893.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7651.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>9270.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>3972.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98005</th>\n",
       "      <td>18904</td>\n",
       "      <td>18710</td>\n",
       "      <td>14550</td>\n",
       "      <td>194</td>\n",
       "      <td>2531</td>\n",
       "      <td>62</td>\n",
       "      <td>105278</td>\n",
       "      <td>146602</td>\n",
       "      <td>60616</td>\n",
       "      <td>707360</td>\n",
       "      <td>755712</td>\n",
       "      <td>7771</td>\n",
       "      <td>2.41</td>\n",
       "      <td>4858</td>\n",
       "      <td>3</td>\n",
       "      <td>8251.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>3521.0</td>\n",
       "      <td>42.7</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98006</th>\n",
       "      <td>40644</td>\n",
       "      <td>40394</td>\n",
       "      <td>35618</td>\n",
       "      <td>250</td>\n",
       "      <td>3800</td>\n",
       "      <td>59</td>\n",
       "      <td>126485</td>\n",
       "      <td>174989</td>\n",
       "      <td>62605</td>\n",
       "      <td>711450</td>\n",
       "      <td>782541</td>\n",
       "      <td>14492</td>\n",
       "      <td>2.79</td>\n",
       "      <td>11329</td>\n",
       "      <td>3</td>\n",
       "      <td>15041.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11513.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>549.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          total_population  population_in_households  population_in_familes  \\\n",
       "zip_code                                                                      \n",
       "98002                35047                     34605                  26256   \n",
       "98003                49533                     48929                  38209   \n",
       "98004                35086                     34949                  24385   \n",
       "98005                18904                     18710                  14550   \n",
       "98006                40644                     40394                  35618   \n",
       "\n",
       "          population_in_group_qrtrs  population_density  diversity_index  \\\n",
       "zip_code                                                                   \n",
       "98002                           442                4906               70   \n",
       "98003                           604                4238               80   \n",
       "98004                           137                4799               56   \n",
       "98005                           194                2531               62   \n",
       "98006                           250                3800               59   \n",
       "\n",
       "          median_household_income  average_household_income  \\\n",
       "zip_code                                                      \n",
       "98002                       47844                     61905   \n",
       "98003                       57052                     76301   \n",
       "98004                      107731                    158537   \n",
       "98005                      105278                    146602   \n",
       "98006                      126485                    174989   \n",
       "\n",
       "          per_capita_income  median_home_value  average_home_value  \\\n",
       "zip_code                                                             \n",
       "98002                 24440             194413              208432   \n",
       "98003                 29554             278121              316089   \n",
       "98004                 76582            1000431             1150686   \n",
       "98005                 60616             707360              755712   \n",
       "98006                 62605             711450              782541   \n",
       "\n",
       "          total_households  average_household_size  family_households  \\\n",
       "zip_code                                                                \n",
       "98002                13599                    2.54               8167   \n",
       "98003                18915                    2.59              11705   \n",
       "98004                16921                    2.07               8508   \n",
       "98005                 7771                    2.41               4858   \n",
       "98006                14492                    2.79              11329   \n",
       "\n",
       "          average_family_size  total_housing_units_#  total_housing_units_%  \\\n",
       "zip_code                                                                      \n",
       "98002                       3                14495.0                  100.0   \n",
       "98003                       3                19978.0                  100.0   \n",
       "98004                       3                20893.0                  100.0   \n",
       "98005                       3                 8251.0                  100.0   \n",
       "98006                       3                15041.0                  100.0   \n",
       "\n",
       "          owner_occupied_housing_units_#  owner_occupied_housing_units_%  \\\n",
       "zip_code                                                                   \n",
       "98002                             6511.0                            44.9   \n",
       "98003                             9320.0                            46.7   \n",
       "98004                             7651.0                            36.6   \n",
       "98005                             4250.0                            51.5   \n",
       "98006                            11513.0                            76.5   \n",
       "\n",
       "          renter_occupied_housing_units_#  renter_occupied_housing_units_%  \\\n",
       "zip_code                                                                     \n",
       "98002                              7088.0                             48.9   \n",
       "98003                              9595.0                             48.0   \n",
       "98004                              9270.0                             44.4   \n",
       "98005                              3521.0                             42.7   \n",
       "98006                              2979.0                             19.8   \n",
       "\n",
       "          vacant_housing_units_#  vacant_housing_units_%  \n",
       "zip_code                                                  \n",
       "98002                      896.0                     6.2  \n",
       "98003                     1063.0                     5.3  \n",
       "98004                     3972.0                    19.0  \n",
       "98005                      480.0                     5.8  \n",
       "98006                      549.0                     3.7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned wslcb data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reporting_period</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>excise_tax_due</th>\n",
       "      <th>name</th>\n",
       "      <th>address1</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>privdesc</th>\n",
       "      <th>privilegestatus</th>\n",
       "      <th>date_issued</th>\n",
       "      <th>phone</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>License #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71368</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>380819.53</td>\n",
       "      <td>140903.23</td>\n",
       "      <td>the herbery</td>\n",
       "      <td>330 NE CHKALOV DR STE C &amp; D</td>\n",
       "      <td>VANCOUVER</td>\n",
       "      <td>WA</td>\n",
       "      <td>CLARK</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>3609079694</td>\n",
       "      <td>98684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76189</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>22331.20</td>\n",
       "      <td>8262.54</td>\n",
       "      <td>pend oreille cannabis co</td>\n",
       "      <td>124 RIVERSIDE AVE</td>\n",
       "      <td>IONE</td>\n",
       "      <td>WA</td>\n",
       "      <td>PEND OREILLE</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>5094423420</td>\n",
       "      <td>99139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79013</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>204078.23</td>\n",
       "      <td>75508.95</td>\n",
       "      <td>pot shop</td>\n",
       "      <td>1628 DEXTER AVE N STE A</td>\n",
       "      <td>SEATTLE</td>\n",
       "      <td>WA</td>\n",
       "      <td>KING</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>PENDING (ISSUED)</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>6145615684</td>\n",
       "      <td>98109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79720</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>124285.72</td>\n",
       "      <td>45985.72</td>\n",
       "      <td>fillabong</td>\n",
       "      <td>3249 PERRY AVE STE B</td>\n",
       "      <td>BREMERTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>KITSAP</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>3604432293</td>\n",
       "      <td>98310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81400</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>76868.21</td>\n",
       "      <td>28441.24</td>\n",
       "      <td>green tiki cannabis</td>\n",
       "      <td>8208 NE STATE HIGHWAY 104</td>\n",
       "      <td>KINGSTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>KITSAP</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>3608810621</td>\n",
       "      <td>98346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reporting_period  total_sales  excise_tax_due  \\\n",
       "License #                                                 \n",
       "71368           2019-02-01    380819.53       140903.23   \n",
       "76189           2019-02-01     22331.20         8262.54   \n",
       "79013           2019-02-01    204078.23        75508.95   \n",
       "79720           2019-02-01    124285.72        45985.72   \n",
       "81400           2019-02-01     76868.21        28441.24   \n",
       "\n",
       "                               name                        address1  \\\n",
       "License #                                                             \n",
       "71368                   the herbery  330 NE CHKALOV DR STE C & D      \n",
       "76189      pend oreille cannabis co  124 RIVERSIDE AVE                \n",
       "79013                      pot shop  1628 DEXTER AVE N STE A          \n",
       "79720                     fillabong  3249 PERRY AVE STE B             \n",
       "81400           green tiki cannabis  8208 NE STATE HIGHWAY 104        \n",
       "\n",
       "                               city state        county  \\\n",
       "License #                                                 \n",
       "71368      VANCOUVER                   WA         CLARK   \n",
       "76189      IONE                        WA  PEND OREILLE   \n",
       "79013      SEATTLE                     WA          KING   \n",
       "79720      BREMERTON                   WA        KITSAP   \n",
       "81400      KINGSTON                    WA        KITSAP   \n",
       "\n",
       "                                      privdesc   privilegestatus date_issued  \\\n",
       "License #                                                                      \n",
       "71368      MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-12-12   \n",
       "76189      MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-10-18   \n",
       "79013      MARIJUANA RETAILER                   PENDING (ISSUED)  2018-09-08   \n",
       "79720      MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-09-13   \n",
       "81400      MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-03-23   \n",
       "\n",
       "                phone zip_code  \n",
       "License #                       \n",
       "71368      3609079694    98684  \n",
       "76189      5094423420    99139  \n",
       "79013      6145615684    98109  \n",
       "79720      3604432293    98310  \n",
       "81400      3608810621    98346  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-591-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-590-43ae17be1488>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mclean_demographic_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mclean_wslcb_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mjoin_cleaned_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mbuild_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-564-2dd124234d44>\u001b[0m in \u001b[0;36mjoin_cleaned_data\u001b[0;34m(path, filename)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m## merge demo data into sales data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zip_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0moutpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interim'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'int_joined'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project2/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     45\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project2/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project2/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m                       (inferred_right in string_types and\n\u001b[1;32m    979\u001b[0m                        inferred_left not in string_types)):\n\u001b[0;32m--> 980\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Setup (delete from here down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 50)\n",
    "path = {\n",
    "    'raw': '../data/raw/',\n",
    "    'interim': '../data/interim/',\n",
    "    'processed': '../data/processed/'\n",
    "}\n",
    "    \n",
    "filename = {\n",
    "    'raw_leafly': 'dispensary_data.json',\n",
    "    'raw_demo': 'demographics.csv',\n",
    "    'raw_license': 'license_data.xls',\n",
    "    'raw_sales': 'sales_data.xlsx',\n",
    "    'int_leafly': 'leafly.pkl',\n",
    "    'int_demo': 'demographics.pkl',\n",
    "    'int_sales': 'sales.pkl',\n",
    "    'int_joined': 'joined_data.pkl',\n",
    "    'processed': 'data.pkl'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Leafly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accessories', 'ada_accessible', 'address1', 'address2', 'all_products',\n",
      "       'atm', 'cartridges', 'city', 'concentrates', 'debit_cards_accepted',\n",
      "       'edibles', 'flower', 'formatted_short_location', 'last_menu_update',\n",
      "       'location', 'medical', 'name', 'number_of_reviews', 'other', 'phone',\n",
      "       'prerolls', 'recreational', 'seeds', 'slug', 'star_rating',\n",
      "       'storefront', 'tier', 'topicals', 'ufcw_discount', 'veteran_discount',\n",
      "       'latitude', 'longitude'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessories</th>\n",
       "      <th>ada_accessible</th>\n",
       "      <th>address1</th>\n",
       "      <th>address2</th>\n",
       "      <th>all_products</th>\n",
       "      <th>atm</th>\n",
       "      <th>cartridges</th>\n",
       "      <th>city</th>\n",
       "      <th>concentrates</th>\n",
       "      <th>debit_cards_accepted</th>\n",
       "      <th>edibles</th>\n",
       "      <th>flower</th>\n",
       "      <th>formatted_short_location</th>\n",
       "      <th>last_menu_update</th>\n",
       "      <th>location</th>\n",
       "      <th>medical</th>\n",
       "      <th>name</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>other</th>\n",
       "      <th>phone</th>\n",
       "      <th>prerolls</th>\n",
       "      <th>recreational</th>\n",
       "      <th>seeds</th>\n",
       "      <th>slug</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>storefront</th>\n",
       "      <th>tier</th>\n",
       "      <th>topicals</th>\n",
       "      <th>ufcw_discount</th>\n",
       "      <th>veteran_discount</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mister Buds</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536 Marine Dr</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port Angeles, WA</td>\n",
       "      <td>2017-04-10 17:54:28.278868+00:00</td>\n",
       "      <td>{'lat': 48.1219849, 'lon': -123.4437221}</td>\n",
       "      <td>0</td>\n",
       "      <td>Mister Buds</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(360) 797-1966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mister-buds</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.121985</td>\n",
       "      <td>-123.443722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origins Port Angeles</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1215 E Front Street</td>\n",
       "      <td>None</td>\n",
       "      <td>621.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port Angeles</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Port Angeles, WA</td>\n",
       "      <td>2019-04-12 01:37:53.395365+00:00</td>\n",
       "      <td>{'lat': 48.1115394, 'lon': -123.4118052}</td>\n",
       "      <td>0</td>\n",
       "      <td>Origins Port Angeles</td>\n",
       "      <td>26</td>\n",
       "      <td>29.0</td>\n",
       "      <td>360.406.4902</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparket-rnr</td>\n",
       "      <td>4.961538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.111539</td>\n",
       "      <td>-123.411805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis Coast</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193161 Highway 101</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forks, WA</td>\n",
       "      <td>2016-04-07 23:37:15.980746+00:00</td>\n",
       "      <td>{'lat': 47.9683179, 'lon': -124.404138}</td>\n",
       "      <td>0</td>\n",
       "      <td>Cannabis Coast</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(360) 374-4020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cannabis-coast</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.968318</td>\n",
       "      <td>-124.404138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lux Pot Shop - Ballard</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4912 17th Ave NW</td>\n",
       "      <td>None</td>\n",
       "      <td>2849.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2019-04-12 00:37:20.749868+00:00</td>\n",
       "      <td>{'lat': 47.6648419, 'lon': -122.3786413}</td>\n",
       "      <td>0</td>\n",
       "      <td>Lux Pot Shop - Ballard</td>\n",
       "      <td>52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>206-294-5586</td>\n",
       "      <td>742.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stash-pot-shop</td>\n",
       "      <td>4.358974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.664842</td>\n",
       "      <td>-122.378641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature's Gifts - Sequim</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>755 W Washington St</td>\n",
       "      <td>Suite C</td>\n",
       "      <td>618.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sequim</td>\n",
       "      <td>262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>Sequim, WA</td>\n",
       "      <td>2019-04-12 03:17:37.187515+00:00</td>\n",
       "      <td>{'lat': 48.0791305, 'lon': -123.1204523}</td>\n",
       "      <td>0</td>\n",
       "      <td>Nature's Gifts - Sequim</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360-797-1993</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>natures-gifts-sequim</td>\n",
       "      <td>4.594737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.079130</td>\n",
       "      <td>-123.120452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accessories ada_accessible             address1  \\\n",
       "Mister Buds                      NaN            NaN        536 Marine Dr   \n",
       "Origins Port Angeles             NaN            1.0  1215 E Front Street   \n",
       "Cannabis Coast                   NaN            NaN   193161 Highway 101   \n",
       "Lux Pot Shop - Ballard           NaN            1.0     4912 17th Ave NW   \n",
       "Nature's Gifts - Sequim          NaN            1.0  755 W Washington St   \n",
       "\n",
       "                        address2  all_products  atm  cartridges          city  \\\n",
       "Mister Buds                 None           NaN  NaN         NaN  Port Angeles   \n",
       "Origins Port Angeles        None         621.0  1.0         NaN  Port Angeles   \n",
       "Cannabis Coast              None           NaN  1.0         NaN         Forks   \n",
       "Lux Pot Shop - Ballard      None        2849.0  1.0         NaN       Seattle   \n",
       "Nature's Gifts - Sequim  Suite C         618.0  1.0         NaN        Sequim   \n",
       "\n",
       "                         concentrates debit_cards_accepted  edibles  flower  \\\n",
       "Mister Buds                       NaN                  NaN      NaN     NaN   \n",
       "Origins Port Angeles            176.0                  NaN    175.0   115.0   \n",
       "Cannabis Coast                    NaN                  NaN      NaN     NaN   \n",
       "Lux Pot Shop - Ballard          634.0                  1.0    765.0   659.0   \n",
       "Nature's Gifts - Sequim         262.0                  NaN     73.0   153.0   \n",
       "\n",
       "                        formatted_short_location  \\\n",
       "Mister Buds                     Port Angeles, WA   \n",
       "Origins Port Angeles            Port Angeles, WA   \n",
       "Cannabis Coast                         Forks, WA   \n",
       "Lux Pot Shop - Ballard               Seattle, WA   \n",
       "Nature's Gifts - Sequim               Sequim, WA   \n",
       "\n",
       "                                        last_menu_update  \\\n",
       "Mister Buds             2017-04-10 17:54:28.278868+00:00   \n",
       "Origins Port Angeles    2019-04-12 01:37:53.395365+00:00   \n",
       "Cannabis Coast          2016-04-07 23:37:15.980746+00:00   \n",
       "Lux Pot Shop - Ballard  2019-04-12 00:37:20.749868+00:00   \n",
       "Nature's Gifts - Sequim 2019-04-12 03:17:37.187515+00:00   \n",
       "\n",
       "                                                         location medical  \\\n",
       "Mister Buds              {'lat': 48.1219849, 'lon': -123.4437221}       0   \n",
       "Origins Port Angeles     {'lat': 48.1115394, 'lon': -123.4118052}       0   \n",
       "Cannabis Coast            {'lat': 47.9683179, 'lon': -124.404138}       0   \n",
       "Lux Pot Shop - Ballard   {'lat': 47.6648419, 'lon': -122.3786413}       0   \n",
       "Nature's Gifts - Sequim  {'lat': 48.0791305, 'lon': -123.1204523}       0   \n",
       "\n",
       "                                            name  number_of_reviews  other  \\\n",
       "Mister Buds                          Mister Buds                  3    NaN   \n",
       "Origins Port Angeles        Origins Port Angeles                 26   29.0   \n",
       "Cannabis Coast                    Cannabis Coast                  2    NaN   \n",
       "Lux Pot Shop - Ballard    Lux Pot Shop - Ballard                 52   49.0   \n",
       "Nature's Gifts - Sequim  Nature's Gifts - Sequim                 19    NaN   \n",
       "\n",
       "                                  phone  prerolls recreational  seeds  \\\n",
       "Mister Buds              (360) 797-1966       NaN            1    NaN   \n",
       "Origins Port Angeles       360.406.4902     126.0            1    NaN   \n",
       "Cannabis Coast           (360) 374-4020       NaN            1    NaN   \n",
       "Lux Pot Shop - Ballard     206-294-5586     742.0            1    NaN   \n",
       "Nature's Gifts - Sequim    360-797-1993     130.0            1    NaN   \n",
       "\n",
       "                                         slug  star_rating storefront  tier  \\\n",
       "Mister Buds                       mister-buds     5.000000        1.0   900   \n",
       "Origins Port Angeles              sparket-rnr     4.961538        1.0   300   \n",
       "Cannabis Coast                 cannabis-coast     5.000000        1.0   900   \n",
       "Lux Pot Shop - Ballard         stash-pot-shop     4.358974        1.0   200   \n",
       "Nature's Gifts - Sequim  natures-gifts-sequim     4.594737        1.0   300   \n",
       "\n",
       "                         topicals ufcw_discount veteran_discount   latitude  \\\n",
       "Mister Buds                   NaN           NaN              NaN  48.121985   \n",
       "Origins Port Angeles          NaN           NaN              1.0  48.111539   \n",
       "Cannabis Coast                NaN           NaN              NaN  47.968318   \n",
       "Lux Pot Shop - Ballard        NaN           NaN              NaN  47.664842   \n",
       "Nature's Gifts - Sequim       NaN           NaN              1.0  48.079130   \n",
       "\n",
       "                          longitude  \n",
       "Mister Buds             -123.443722  \n",
       "Origins Port Angeles    -123.411805  \n",
       "Cannabis Coast          -124.404138  \n",
       "Lux Pot Shop - Ballard  -122.378641  \n",
       "Nature's Gifts - Sequim -123.120452  "
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_filename = path['raw'] + filename['raw_leafly']\n",
    "int_filename = path['interim'] + filename['int_leafly']\n",
    "\n",
    "# Read data from file to dataframe\n",
    "data = pd.read_json(raw_filename, orient='index')\n",
    "\n",
    "# Rename columns\n",
    "data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "data.rename(columns={\n",
    "    'formattedshortlocation': 'formatted_short_location', \n",
    "    'lastmenuupdate': 'last_menu_update',\n",
    "    'numberofreviews': 'number_of_reviews',\n",
    "    'pre-rolls': 'prerolls',\n",
    "    'starrating': 'star_rating'\n",
    "}, inplace=True)\n",
    "\n",
    "# Filter to only Washington entries\n",
    "f = data['formatted_short_location'].str.contains('WA')\n",
    "data = data[f]\n",
    "\n",
    "# Cast menu update as datetime\n",
    "data['last_menu_update'] = pd.to_datetime(\n",
    "    data['last_menu_update'], errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# Cast categorical features as such\n",
    "cat_cols = ['ada_accessible', 'atm', 'debit_cards_accepted', 'medical', \n",
    "            'recreational', 'storefront', 'ufcw_discount', \n",
    "            'veteran_discount']\n",
    "data[cat_cols] = data[cat_cols].astype('category')\n",
    "\n",
    "# Extact lat/lon coordinates into their own feature\n",
    "data[['latitude', 'longitude']] = data['location'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_housing_units ['total_housing_units_#', 'total_housing_units_%']\n",
      "owner_occupied_housing_units ['owner_occupied_housing_units_#', 'owner_occupied_housing_units_%']\n",
      "renter_occupied_housing_units ['renter_occupied_housing_units_#', 'renter_occupied_housing_units_%']\n",
      "vacant_housing_units ['vacant_housing_units_#', 'vacant_housing_units_%']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_population</th>\n",
       "      <th>population_in_households</th>\n",
       "      <th>population_in_familes</th>\n",
       "      <th>population_in_group_qrtrs</th>\n",
       "      <th>population_density</th>\n",
       "      <th>diversity_index</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>average_household_income</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>median_home_value</th>\n",
       "      <th>average_home_value</th>\n",
       "      <th>total_households</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>family_households</th>\n",
       "      <th>average_family_size</th>\n",
       "      <th>total_housing_units_#</th>\n",
       "      <th>total_housing_units_%</th>\n",
       "      <th>owner_occupied_housing_units_#</th>\n",
       "      <th>owner_occupied_housing_units_%</th>\n",
       "      <th>renter_occupied_housing_units_#</th>\n",
       "      <th>renter_occupied_housing_units_%</th>\n",
       "      <th>vacant_housing_units_#</th>\n",
       "      <th>vacant_housing_units_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98002</th>\n",
       "      <td>35047</td>\n",
       "      <td>34605</td>\n",
       "      <td>26256</td>\n",
       "      <td>442</td>\n",
       "      <td>4906</td>\n",
       "      <td>70</td>\n",
       "      <td>47844</td>\n",
       "      <td>61905</td>\n",
       "      <td>24440</td>\n",
       "      <td>194413</td>\n",
       "      <td>208432</td>\n",
       "      <td>13599</td>\n",
       "      <td>2.54</td>\n",
       "      <td>8167</td>\n",
       "      <td>3</td>\n",
       "      <td>14495.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6511.0</td>\n",
       "      <td>44.9</td>\n",
       "      <td>7088.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>896.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98003</th>\n",
       "      <td>49533</td>\n",
       "      <td>48929</td>\n",
       "      <td>38209</td>\n",
       "      <td>604</td>\n",
       "      <td>4238</td>\n",
       "      <td>80</td>\n",
       "      <td>57052</td>\n",
       "      <td>76301</td>\n",
       "      <td>29554</td>\n",
       "      <td>278121</td>\n",
       "      <td>316089</td>\n",
       "      <td>18915</td>\n",
       "      <td>2.59</td>\n",
       "      <td>11705</td>\n",
       "      <td>3</td>\n",
       "      <td>19978.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>46.7</td>\n",
       "      <td>9595.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98004</th>\n",
       "      <td>35086</td>\n",
       "      <td>34949</td>\n",
       "      <td>24385</td>\n",
       "      <td>137</td>\n",
       "      <td>4799</td>\n",
       "      <td>56</td>\n",
       "      <td>107731</td>\n",
       "      <td>158537</td>\n",
       "      <td>76582</td>\n",
       "      <td>1000431</td>\n",
       "      <td>1150686</td>\n",
       "      <td>16921</td>\n",
       "      <td>2.07</td>\n",
       "      <td>8508</td>\n",
       "      <td>3</td>\n",
       "      <td>20893.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7651.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>9270.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>3972.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98005</th>\n",
       "      <td>18904</td>\n",
       "      <td>18710</td>\n",
       "      <td>14550</td>\n",
       "      <td>194</td>\n",
       "      <td>2531</td>\n",
       "      <td>62</td>\n",
       "      <td>105278</td>\n",
       "      <td>146602</td>\n",
       "      <td>60616</td>\n",
       "      <td>707360</td>\n",
       "      <td>755712</td>\n",
       "      <td>7771</td>\n",
       "      <td>2.41</td>\n",
       "      <td>4858</td>\n",
       "      <td>3</td>\n",
       "      <td>8251.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>3521.0</td>\n",
       "      <td>42.7</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98006</th>\n",
       "      <td>40644</td>\n",
       "      <td>40394</td>\n",
       "      <td>35618</td>\n",
       "      <td>250</td>\n",
       "      <td>3800</td>\n",
       "      <td>59</td>\n",
       "      <td>126485</td>\n",
       "      <td>174989</td>\n",
       "      <td>62605</td>\n",
       "      <td>711450</td>\n",
       "      <td>782541</td>\n",
       "      <td>14492</td>\n",
       "      <td>2.79</td>\n",
       "      <td>11329</td>\n",
       "      <td>3</td>\n",
       "      <td>15041.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11513.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>549.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          total_population  population_in_households  population_in_familes  \\\n",
       "zip_code                                                                      \n",
       "98002                35047                     34605                  26256   \n",
       "98003                49533                     48929                  38209   \n",
       "98004                35086                     34949                  24385   \n",
       "98005                18904                     18710                  14550   \n",
       "98006                40644                     40394                  35618   \n",
       "\n",
       "          population_in_group_qrtrs  population_density  diversity_index  \\\n",
       "zip_code                                                                   \n",
       "98002                           442                4906               70   \n",
       "98003                           604                4238               80   \n",
       "98004                           137                4799               56   \n",
       "98005                           194                2531               62   \n",
       "98006                           250                3800               59   \n",
       "\n",
       "          median_household_income  average_household_income  \\\n",
       "zip_code                                                      \n",
       "98002                       47844                     61905   \n",
       "98003                       57052                     76301   \n",
       "98004                      107731                    158537   \n",
       "98005                      105278                    146602   \n",
       "98006                      126485                    174989   \n",
       "\n",
       "          per_capita_income  median_home_value  average_home_value  \\\n",
       "zip_code                                                             \n",
       "98002                 24440             194413              208432   \n",
       "98003                 29554             278121              316089   \n",
       "98004                 76582            1000431             1150686   \n",
       "98005                 60616             707360              755712   \n",
       "98006                 62605             711450              782541   \n",
       "\n",
       "          total_households  average_household_size  family_households  \\\n",
       "zip_code                                                                \n",
       "98002                13599                    2.54               8167   \n",
       "98003                18915                    2.59              11705   \n",
       "98004                16921                    2.07               8508   \n",
       "98005                 7771                    2.41               4858   \n",
       "98006                14492                    2.79              11329   \n",
       "\n",
       "          average_family_size  total_housing_units_#  total_housing_units_%  \\\n",
       "zip_code                                                                      \n",
       "98002                       3                14495.0                  100.0   \n",
       "98003                       3                19978.0                  100.0   \n",
       "98004                       3                20893.0                  100.0   \n",
       "98005                       3                 8251.0                  100.0   \n",
       "98006                       3                15041.0                  100.0   \n",
       "\n",
       "          owner_occupied_housing_units_#  owner_occupied_housing_units_%  \\\n",
       "zip_code                                                                   \n",
       "98002                             6511.0                            44.9   \n",
       "98003                             9320.0                            46.7   \n",
       "98004                             7651.0                            36.6   \n",
       "98005                             4250.0                            51.5   \n",
       "98006                            11513.0                            76.5   \n",
       "\n",
       "          renter_occupied_housing_units_#  renter_occupied_housing_units_%  \\\n",
       "zip_code                                                                     \n",
       "98002                              7088.0                             48.9   \n",
       "98003                              9595.0                             48.0   \n",
       "98004                              9270.0                             44.4   \n",
       "98005                              3521.0                             42.7   \n",
       "98006                              2979.0                             19.8   \n",
       "\n",
       "          vacant_housing_units_#  vacant_housing_units_%  \n",
       "zip_code                                                  \n",
       "98002                      896.0                     6.2  \n",
       "98003                     1063.0                     5.3  \n",
       "98004                     3972.0                    19.0  \n",
       "98005                      480.0                     5.8  \n",
       "98006                      549.0                     3.7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 243 entries, 98002 to 99403\n",
      "Data columns (total 23 columns):\n",
      "total_population                   243 non-null int64\n",
      "population_in_households           243 non-null int64\n",
      "population_in_familes              243 non-null int64\n",
      "population_in_group_qrtrs          243 non-null int64\n",
      "population_density                 243 non-null int64\n",
      "diversity_index                    243 non-null int64\n",
      "median_household_income            243 non-null int64\n",
      "average_household_income           243 non-null int64\n",
      "per_capita_income                  243 non-null int64\n",
      "median_home_value                  243 non-null int64\n",
      "average_home_value                 243 non-null int64\n",
      "total_households                   243 non-null int64\n",
      "average_household_size             243 non-null float64\n",
      "family_households                  243 non-null int64\n",
      "average_family_size                243 non-null int64\n",
      "total_housing_units_#              243 non-null float64\n",
      "total_housing_units_%              243 non-null float64\n",
      "owner_occupied_housing_units_#     243 non-null float64\n",
      "owner_occupied_housing_units_%     243 non-null float64\n",
      "renter_occupied_housing_units_#    243 non-null float64\n",
      "renter_occupied_housing_units_%    243 non-null float64\n",
      "vacant_housing_units_#             243 non-null float64\n",
      "vacant_housing_units_%             243 non-null float64\n",
      "dtypes: float64(9), int64(14)\n",
      "memory usage: 45.6 KB\n"
     ]
    }
   ],
   "source": [
    "raw_filename = path['raw'] + filename['raw_demo']\n",
    "int_filename = path['interim'] + filename['int_demo']\n",
    "\n",
    "data = pd.read_csv(raw_filename)\n",
    "\n",
    "# Reformat column\n",
    "data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "data.rename(columns={\n",
    "    'unnamed:_0': 'zip_code', \n",
    "    'population_density2': 'population_density',\n",
    "    'diversity_index3': 'diversity_index',\n",
    "    'owner_occupied_hu': 'owner_occupied_housing_units',\n",
    "    'renter_occupied_hu': 'renter_occupied_housing_units'\n",
    "}, inplace=True)\n",
    "data.set_index('zip_code', drop=True, inplace=True)\n",
    "\n",
    "# Reformat columns with dollar strings into ints\n",
    "cols = ['median_household_income', 'average_household_income',\n",
    "        'per_capita_income', 'median_home_value', 'average_home_value']\n",
    "for c in cols:\n",
    "    data[c] = data[c].str.replace('$', '').str.replace(',', '').astype(int)\n",
    "\n",
    "# Split columns with number and percent values into separate columns\n",
    "cols = ['total_housing_units', 'owner_occupied_housing_units', \n",
    "        'renter_occupied_housing_units', 'vacant_housing_units']\n",
    "new_cols = {col:[f'{col}_#', f'{col}_%'] for col in cols}\n",
    "for old, new in new_cols.items():\n",
    "    for char in list(',(%)'):\n",
    "        data[old] = data[old].str.replace(char, '')\n",
    "    print(old, new)\n",
    "    data[new] = data[old].str.split().apply(pd.Series).astype(float)\n",
    "\n",
    "# Drop old columns we don't want anymore\n",
    "cols = ['total_housing_units', 'owner_occupied_housing_units', \n",
    "        'renter_occupied_housing_units', 'vacant_housing_units']\n",
    "data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_population', 'population_in_households', 'population_in_familes',\n",
       "       'population_in_group_qrtrs', 'population_density', 'diversity_index',\n",
       "       'median_household_income', 'average_household_income',\n",
       "       'per_capita_income', 'total_housing_units',\n",
       "       'owner_occupied_housing_units', 'renter_occupied_housing_units',\n",
       "       'vacant_housing_units', 'median_home_value', 'average_home_value',\n",
       "       'total_households', 'average_household_size', 'family_households',\n",
       "       'average_family_size', 'total_housing_units_#', 'total_housing_units_%',\n",
       "       'owner_occupied_housing_units_#', 'owner_occupied_housing_units_%',\n",
       "       'renter_occupied_housing_units_#', 'renter_occupied_housing_units_%',\n",
       "       'vacant_housing_units_#', 'vacant_housing_units_%'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Sales and License data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reporting_period', 'total_sales', 'excise_tax_due', 'name', 'ubi',\n",
       "       'street_address', 'suite/rm', 'city', 'state', 'county', 'zipcode',\n",
       "       'privdesc', 'privilegestatus', 'dateissued', 'dayphone', 'zip_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reporting period', 'total sales', 'excise tax due', 'tradename', 'ubi',\n",
       "       'street address', 'suite/rm', 'city', 'state', 'county', 'zipcode',\n",
       "       'privdesc', 'privilegestatus', 'dateissued', 'dayphone', 'zip_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reporting_period</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>excise_tax_due</th>\n",
       "      <th>name</th>\n",
       "      <th>ubi</th>\n",
       "      <th>street_address</th>\n",
       "      <th>suite/rm</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>privdesc</th>\n",
       "      <th>privilegestatus</th>\n",
       "      <th>date_issued</th>\n",
       "      <th>phone</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>address1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>License #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414884</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>237642.93</td>\n",
       "      <td>87927.88</td>\n",
       "      <td>#hashtag</td>\n",
       "      <td>6.033581e+15</td>\n",
       "      <td>3540 STONE WAY N</td>\n",
       "      <td></td>\n",
       "      <td>SEATTLE</td>\n",
       "      <td>WA</td>\n",
       "      <td>KING</td>\n",
       "      <td>981038924.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>3.608184e+09</td>\n",
       "      <td>98103</td>\n",
       "      <td>3540 STONE WAY N                              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423413</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>463721.35</td>\n",
       "      <td>171576.90</td>\n",
       "      <td>112th street cannabis</td>\n",
       "      <td>6.033492e+15</td>\n",
       "      <td>5809 112TH ST E BLDG B</td>\n",
       "      <td></td>\n",
       "      <td>PUYALLUP</td>\n",
       "      <td>WA</td>\n",
       "      <td>PIERCE</td>\n",
       "      <td>983734323.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-12-22</td>\n",
       "      <td>2.069924e+09</td>\n",
       "      <td>98373</td>\n",
       "      <td>5809 112TH ST E BLDG B                        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364799</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>217209.85</td>\n",
       "      <td>80367.64</td>\n",
       "      <td>2020 solutions edmonds</td>\n",
       "      <td>6.035723e+15</td>\n",
       "      <td>7207 212TH ST SW</td>\n",
       "      <td></td>\n",
       "      <td>EDMONDS</td>\n",
       "      <td>WA</td>\n",
       "      <td>SNOHOMISH</td>\n",
       "      <td>980207735.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>3.609155e+09</td>\n",
       "      <td>98020</td>\n",
       "      <td>7207 212TH ST SW                              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422239</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>60398.07</td>\n",
       "      <td>22347.29</td>\n",
       "      <td>2020 solutions ephrata</td>\n",
       "      <td>6.035723e+15</td>\n",
       "      <td>1615 BASIN ST SW</td>\n",
       "      <td></td>\n",
       "      <td>EPHRATA</td>\n",
       "      <td>WA</td>\n",
       "      <td>GRANT</td>\n",
       "      <td>988232134.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>3.609155e+09</td>\n",
       "      <td>98823</td>\n",
       "      <td>1615 BASIN ST SW                              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422363</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>27246.27</td>\n",
       "      <td>10081.12</td>\n",
       "      <td>2020 solutions soap lake</td>\n",
       "      <td>6.035723e+15</td>\n",
       "      <td>261 STATE HWY 28 WEST</td>\n",
       "      <td></td>\n",
       "      <td>SOAP LAKE</td>\n",
       "      <td>WA</td>\n",
       "      <td>GRANT</td>\n",
       "      <td>988510000.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>3.609155e+09</td>\n",
       "      <td>98851</td>\n",
       "      <td>261 STATE HWY 28 WEST                         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422701</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>4795.38</td>\n",
       "      <td>1774.29</td>\n",
       "      <td>2020 solutions sprague</td>\n",
       "      <td>6.036007e+15</td>\n",
       "      <td>209 E 4TH ST SUITE B</td>\n",
       "      <td></td>\n",
       "      <td>SPRAGUE</td>\n",
       "      <td>WA</td>\n",
       "      <td>LINCOLN</td>\n",
       "      <td>990320000.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2.534052e+09</td>\n",
       "      <td>99032</td>\n",
       "      <td>209 E 4TH ST SUITE B                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425128</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>13244.29</td>\n",
       "      <td>4900.39</td>\n",
       "      <td>20after4</td>\n",
       "      <td>6.033493e+15</td>\n",
       "      <td>302 HAZEL ST</td>\n",
       "      <td></td>\n",
       "      <td>KELSO</td>\n",
       "      <td>WA</td>\n",
       "      <td>COWLITZ</td>\n",
       "      <td>986261410.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>PENDING (ISSUED)</td>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>2.069293e+09</td>\n",
       "      <td>98626</td>\n",
       "      <td>302 HAZEL ST                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423784</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>203110.98</td>\n",
       "      <td>75151.06</td>\n",
       "      <td>365 recreational cannabis</td>\n",
       "      <td>6.034297e+15</td>\n",
       "      <td>17517 15TH AVE NE #B</td>\n",
       "      <td></td>\n",
       "      <td>SHORELINE</td>\n",
       "      <td>WA</td>\n",
       "      <td>KING</td>\n",
       "      <td>981553801.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>4.259194e+09</td>\n",
       "      <td>98155</td>\n",
       "      <td>17517 15TH AVE NE #B                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422099</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>55461.39</td>\n",
       "      <td>20520.71</td>\n",
       "      <td>365 recreational cannabis</td>\n",
       "      <td>6.041521e+15</td>\n",
       "      <td>36711 U.S. HIGHWAY 12</td>\n",
       "      <td></td>\n",
       "      <td>DAYTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>COLUMBIA</td>\n",
       "      <td>983288622.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>5.093823e+09</td>\n",
       "      <td>98328</td>\n",
       "      <td>36711 U.S. HIGHWAY 12                         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424848</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>465377.75</td>\n",
       "      <td>172189.77</td>\n",
       "      <td>420 capitol</td>\n",
       "      <td>6.035341e+15</td>\n",
       "      <td>5980 CAPITOL BLVD SE</td>\n",
       "      <td></td>\n",
       "      <td>TUMWATER</td>\n",
       "      <td>WA</td>\n",
       "      <td>THURSTON</td>\n",
       "      <td>985015274.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>3.604026e+09</td>\n",
       "      <td>98501</td>\n",
       "      <td>5980 CAPITOL BLVD SE                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415083</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>611288.67</td>\n",
       "      <td>226176.81</td>\n",
       "      <td>420 carpenter</td>\n",
       "      <td>6.033585e+15</td>\n",
       "      <td>422 CARPENTER RD STE 105</td>\n",
       "      <td></td>\n",
       "      <td>LACEY</td>\n",
       "      <td>WA</td>\n",
       "      <td>THURSTON</td>\n",
       "      <td>985037906.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>3.604026e+09</td>\n",
       "      <td>98503</td>\n",
       "      <td>422 CARPENTER RD STE 105                      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426678</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>110317.78</td>\n",
       "      <td>40817.58</td>\n",
       "      <td>420 elma on main</td>\n",
       "      <td>6.035793e+15</td>\n",
       "      <td>306 W MAIN ST</td>\n",
       "      <td></td>\n",
       "      <td>ELMA</td>\n",
       "      <td>WA</td>\n",
       "      <td>GRAYS HARBOR</td>\n",
       "      <td>985410000.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>3.605617e+09</td>\n",
       "      <td>98541</td>\n",
       "      <td>306 W MAIN ST                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427533</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>38104.79</td>\n",
       "      <td>14098.77</td>\n",
       "      <td>420 evergreen</td>\n",
       "      <td>6.033591e+15</td>\n",
       "      <td>25 NE 2ND ST STE B</td>\n",
       "      <td>SUITE B</td>\n",
       "      <td>STEVENSON</td>\n",
       "      <td>WA</td>\n",
       "      <td>SKAMANIA</td>\n",
       "      <td>986484215.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>PENDING (ISSUED)</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>4.842266e+09</td>\n",
       "      <td>98648</td>\n",
       "      <td>25 NE 2ND ST STE B            SUITE B         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415526</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>291672.91</td>\n",
       "      <td>107918.98</td>\n",
       "      <td>420 holiday</td>\n",
       "      <td>6.033592e+15</td>\n",
       "      <td>2028 10TH AVE</td>\n",
       "      <td></td>\n",
       "      <td>LONGVIEW</td>\n",
       "      <td>WA</td>\n",
       "      <td>COWLITZ</td>\n",
       "      <td>986324007.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>3.607033e+09</td>\n",
       "      <td>98632</td>\n",
       "      <td>2028 10TH AVE                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414550</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>134467.35</td>\n",
       "      <td>49752.92</td>\n",
       "      <td>420 spot shop</td>\n",
       "      <td>6.034052e+15</td>\n",
       "      <td>1374 SE LUND AVE</td>\n",
       "      <td></td>\n",
       "      <td>PORT ORCHARD</td>\n",
       "      <td>WA</td>\n",
       "      <td>KITSAP</td>\n",
       "      <td>983665628.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>3.603406e+09</td>\n",
       "      <td>98366</td>\n",
       "      <td>1374 SE LUND AVE                              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423372</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>303307.49</td>\n",
       "      <td>112223.77</td>\n",
       "      <td>420 tacoma</td>\n",
       "      <td>6.034798e+15</td>\n",
       "      <td>2128 S 37TH ST</td>\n",
       "      <td></td>\n",
       "      <td>TACOMA</td>\n",
       "      <td>WA</td>\n",
       "      <td>PIERCE</td>\n",
       "      <td>984097445.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>3.604026e+09</td>\n",
       "      <td>98409</td>\n",
       "      <td>2128 S 37TH ST                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414733</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>303070.33</td>\n",
       "      <td>112136.02</td>\n",
       "      <td>420 west</td>\n",
       "      <td>6.033585e+15</td>\n",
       "      <td>410 RONLEE LN NW A1</td>\n",
       "      <td></td>\n",
       "      <td>OLYMPIA</td>\n",
       "      <td>WA</td>\n",
       "      <td>THURSTON</td>\n",
       "      <td>985029266.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>3.604026e+09</td>\n",
       "      <td>98502</td>\n",
       "      <td>410 RONLEE LN NW A1                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413586</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>79896.53</td>\n",
       "      <td>29561.72</td>\n",
       "      <td>4:20 friendly</td>\n",
       "      <td>6.033516e+15</td>\n",
       "      <td>1515 LEWIS ST</td>\n",
       "      <td></td>\n",
       "      <td>SPOKANE</td>\n",
       "      <td>WA</td>\n",
       "      <td>SPOKANE</td>\n",
       "      <td>992249785.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>5.094991e+09</td>\n",
       "      <td>99224</td>\n",
       "      <td>1515 LEWIS ST                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421491</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>90074.06</td>\n",
       "      <td>33327.40</td>\n",
       "      <td>a &amp; j management group</td>\n",
       "      <td>6.032946e+15</td>\n",
       "      <td>234 DIVISION ST NW STE B</td>\n",
       "      <td></td>\n",
       "      <td>OLYMPIA</td>\n",
       "      <td>WA</td>\n",
       "      <td>THURSTON</td>\n",
       "      <td>985024916.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>5.055508e+09</td>\n",
       "      <td>98502</td>\n",
       "      <td>234 DIVISION ST NW STE B                      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414441</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>315156.91</td>\n",
       "      <td>116608.06</td>\n",
       "      <td>a greener today marijuana</td>\n",
       "      <td>6.034501e+15</td>\n",
       "      <td>5209 MARTIN LUTHER KING JR.</td>\n",
       "      <td>WAY S</td>\n",
       "      <td>SEATTLE</td>\n",
       "      <td>WA</td>\n",
       "      <td>KING</td>\n",
       "      <td>981186131.0</td>\n",
       "      <td>MARIJUANA RETAILER</td>\n",
       "      <td>ACTIVE (ISSUED)</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>4.257736e+09</td>\n",
       "      <td>98118</td>\n",
       "      <td>5209 MARTIN LUTHER KING JR.   WAY S           ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reporting_period  total_sales  excise_tax_due  \\\n",
       "License #                                                 \n",
       "414884          2019-02-01    237642.93        87927.88   \n",
       "423413          2019-02-01    463721.35       171576.90   \n",
       "364799          2019-02-01    217209.85        80367.64   \n",
       "422239          2019-02-01     60398.07        22347.29   \n",
       "422363          2019-02-01     27246.27        10081.12   \n",
       "422701          2019-02-01      4795.38         1774.29   \n",
       "425128          2019-02-01     13244.29         4900.39   \n",
       "423784          2019-02-01    203110.98        75151.06   \n",
       "422099          2019-02-01     55461.39        20520.71   \n",
       "424848          2019-02-01    465377.75       172189.77   \n",
       "415083          2019-02-01    611288.67       226176.81   \n",
       "426678          2019-02-01    110317.78        40817.58   \n",
       "427533          2019-02-01     38104.79        14098.77   \n",
       "415526          2019-02-01    291672.91       107918.98   \n",
       "414550          2019-02-01    134467.35        49752.92   \n",
       "423372          2019-02-01    303307.49       112223.77   \n",
       "414733          2019-02-01    303070.33       112136.02   \n",
       "413586          2019-02-01     79896.53        29561.72   \n",
       "421491          2019-02-01     90074.06        33327.40   \n",
       "414441          2019-02-01    315156.91       116608.06   \n",
       "\n",
       "                                name           ubi  \\\n",
       "License #                                            \n",
       "414884                      #hashtag  6.033581e+15   \n",
       "423413         112th street cannabis  6.033492e+15   \n",
       "364799        2020 solutions edmonds  6.035723e+15   \n",
       "422239        2020 solutions ephrata  6.035723e+15   \n",
       "422363      2020 solutions soap lake  6.035723e+15   \n",
       "422701        2020 solutions sprague  6.036007e+15   \n",
       "425128                      20after4  6.033493e+15   \n",
       "423784     365 recreational cannabis  6.034297e+15   \n",
       "422099     365 recreational cannabis  6.041521e+15   \n",
       "424848                   420 capitol  6.035341e+15   \n",
       "415083                 420 carpenter  6.033585e+15   \n",
       "426678              420 elma on main  6.035793e+15   \n",
       "427533                 420 evergreen  6.033591e+15   \n",
       "415526                   420 holiday  6.033592e+15   \n",
       "414550                 420 spot shop  6.034052e+15   \n",
       "423372                    420 tacoma  6.034798e+15   \n",
       "414733                      420 west  6.033585e+15   \n",
       "413586                 4:20 friendly  6.033516e+15   \n",
       "421491        a & j management group  6.032946e+15   \n",
       "414441     a greener today marijuana  6.034501e+15   \n",
       "\n",
       "                           street_address                   suite/rm  \\\n",
       "License #                                                              \n",
       "414884     3540 STONE WAY N                                            \n",
       "423413     5809 112TH ST E BLDG B                                      \n",
       "364799     7207 212TH ST SW                                            \n",
       "422239     1615 BASIN ST SW                                            \n",
       "422363     261 STATE HWY 28 WEST                                       \n",
       "422701     209 E 4TH ST SUITE B                                        \n",
       "425128     302 HAZEL ST                                                \n",
       "423784     17517 15TH AVE NE #B                                        \n",
       "422099     36711 U.S. HIGHWAY 12                                       \n",
       "424848     5980 CAPITOL BLVD SE                                        \n",
       "415083     422 CARPENTER RD STE 105                                    \n",
       "426678     306 W MAIN ST                                               \n",
       "427533     25 NE 2ND ST STE B              SUITE B                     \n",
       "415526     2028 10TH AVE                                               \n",
       "414550     1374 SE LUND AVE                                            \n",
       "423372     2128 S 37TH ST                                              \n",
       "414733     410 RONLEE LN NW A1                                         \n",
       "413586     1515 LEWIS ST                                               \n",
       "421491     234 DIVISION ST NW STE B                                    \n",
       "414441     5209 MARTIN LUTHER KING JR.     WAY S                       \n",
       "\n",
       "                               city state        county      zipcode  \\\n",
       "License #                                                              \n",
       "414884     SEATTLE                     WA          KING  981038924.0   \n",
       "423413     PUYALLUP                    WA        PIERCE  983734323.0   \n",
       "364799     EDMONDS                     WA     SNOHOMISH  980207735.0   \n",
       "422239     EPHRATA                     WA         GRANT  988232134.0   \n",
       "422363     SOAP LAKE                   WA         GRANT  988510000.0   \n",
       "422701     SPRAGUE                     WA       LINCOLN  990320000.0   \n",
       "425128     KELSO                       WA       COWLITZ  986261410.0   \n",
       "423784     SHORELINE                   WA          KING  981553801.0   \n",
       "422099     DAYTON                      WA      COLUMBIA  983288622.0   \n",
       "424848     TUMWATER                    WA      THURSTON  985015274.0   \n",
       "415083     LACEY                       WA      THURSTON  985037906.0   \n",
       "426678     ELMA                        WA  GRAYS HARBOR  985410000.0   \n",
       "427533     STEVENSON                   WA      SKAMANIA  986484215.0   \n",
       "415526     LONGVIEW                    WA       COWLITZ  986324007.0   \n",
       "414550     PORT ORCHARD                WA        KITSAP  983665628.0   \n",
       "423372     TACOMA                      WA        PIERCE  984097445.0   \n",
       "414733     OLYMPIA                     WA      THURSTON  985029266.0   \n",
       "413586     SPOKANE                     WA       SPOKANE  992249785.0   \n",
       "421491     OLYMPIA                     WA      THURSTON  985024916.0   \n",
       "414441     SEATTLE                     WA          KING  981186131.0   \n",
       "\n",
       "                                      privdesc   privilegestatus date_issued  \\\n",
       "License #                                                                      \n",
       "414884     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-11-29   \n",
       "423413     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-12-22   \n",
       "364799     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-03-26   \n",
       "422239     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-12-08   \n",
       "422363     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-12-08   \n",
       "422701     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-03-26   \n",
       "425128     MARIJUANA RETAILER                   PENDING (ISSUED)  2018-11-22   \n",
       "423784     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-07-19   \n",
       "422099     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-04-03   \n",
       "424848     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-07-19   \n",
       "415083     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-12-25   \n",
       "426678     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-03-14   \n",
       "427533     MARIJUANA RETAILER                   PENDING (ISSUED)  2019-01-17   \n",
       "415526     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-12-04   \n",
       "414550     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-04-06   \n",
       "423372     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-01-29   \n",
       "414733     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-12-25   \n",
       "413586     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-10-24   \n",
       "421491     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2019-02-22   \n",
       "414441     MARIJUANA RETAILER                    ACTIVE (ISSUED)  2018-10-12   \n",
       "\n",
       "                  phone zip_code  \\\n",
       "License #                          \n",
       "414884     3.608184e+09    98103   \n",
       "423413     2.069924e+09    98373   \n",
       "364799     3.609155e+09    98020   \n",
       "422239     3.609155e+09    98823   \n",
       "422363     3.609155e+09    98851   \n",
       "422701     2.534052e+09    99032   \n",
       "425128     2.069293e+09    98626   \n",
       "423784     4.259194e+09    98155   \n",
       "422099     5.093823e+09    98328   \n",
       "424848     3.604026e+09    98501   \n",
       "415083     3.604026e+09    98503   \n",
       "426678     3.605617e+09    98541   \n",
       "427533     4.842266e+09    98648   \n",
       "415526     3.607033e+09    98632   \n",
       "414550     3.603406e+09    98366   \n",
       "423372     3.604026e+09    98409   \n",
       "414733     3.604026e+09    98502   \n",
       "413586     5.094991e+09    99224   \n",
       "421491     5.055508e+09    98502   \n",
       "414441     4.257736e+09    98118   \n",
       "\n",
       "                                                    address1  \n",
       "License #                                                     \n",
       "414884     3540 STONE WAY N                              ...  \n",
       "423413     5809 112TH ST E BLDG B                        ...  \n",
       "364799     7207 212TH ST SW                              ...  \n",
       "422239     1615 BASIN ST SW                              ...  \n",
       "422363     261 STATE HWY 28 WEST                         ...  \n",
       "422701     209 E 4TH ST SUITE B                          ...  \n",
       "425128     302 HAZEL ST                                  ...  \n",
       "423784     17517 15TH AVE NE #B                          ...  \n",
       "422099     36711 U.S. HIGHWAY 12                         ...  \n",
       "424848     5980 CAPITOL BLVD SE                          ...  \n",
       "415083     422 CARPENTER RD STE 105                      ...  \n",
       "426678     306 W MAIN ST                                 ...  \n",
       "427533     25 NE 2ND ST STE B            SUITE B         ...  \n",
       "415526     2028 10TH AVE                                 ...  \n",
       "414550     1374 SE LUND AVE                              ...  \n",
       "423372     2128 S 37TH ST                                ...  \n",
       "414733     410 RONLEE LN NW A1                           ...  \n",
       "413586     1515 LEWIS ST                                 ...  \n",
       "421491     234 DIVISION ST NW STE B                      ...  \n",
       "414441     5209 MARTIN LUTHER KING JR.   WAY S           ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 417 entries, 71368 to 428005\n",
      "Data columns (total 17 columns):\n",
      "reporting_period    417 non-null datetime64[ns]\n",
      "total_sales         417 non-null float64\n",
      "excise_tax_due      417 non-null float64\n",
      "name                415 non-null object\n",
      "ubi                 415 non-null float64\n",
      "street_address      415 non-null object\n",
      "suite/rm            415 non-null object\n",
      "city                415 non-null object\n",
      "state               415 non-null object\n",
      "county              415 non-null object\n",
      "zipcode             415 non-null float64\n",
      "privdesc            415 non-null object\n",
      "privilegestatus     415 non-null object\n",
      "date_issued         410 non-null datetime64[ns]\n",
      "phone               415 non-null float64\n",
      "zip_code            417 non-null object\n",
      "address1            415 non-null object\n",
      "dtypes: datetime64[ns](2), float64(5), object(10)\n",
      "memory usage: 58.6+ KB\n"
     ]
    }
   ],
   "source": [
    "sales_data = join_sales_data(path, filename)\n",
    "sales_data.columns = sales_data.columns.str.lower().str.replace(' ', '_')\n",
    "sales_data.rename(columns={\n",
    "    'tradename': 'name', \n",
    "    'dateissued': 'date_issued',\n",
    "    'dayphone': 'phone',\n",
    "}, inplace=True)\n",
    "\n",
    "sales_data['zip_code'] = sales_data['zipcode'].astype(str).str[:5]\n",
    "sales_data['name'] = sales_data['name'].str.strip().str.lower()\n",
    "sales_data['address1'] = sales_data['street_address'] + sales_data['suite/rm']\n",
    "\n",
    "sales_data['reporting_period'] += '-01'\n",
    "date_cols = ['reporting_period', 'date_issued']\n",
    "for col in date_cols:\n",
    "    sales_data[col] = pd.to_datetime(sales_data[col], errors='coerce', \n",
    "                                     yearfirst=True, infer_datetime_format=True)\n",
    "\n",
    "recent = sales_data['reporting_period'] == sales_data['reporting_period'].max()\n",
    "recent_sales = sales_data[recent]\n",
    "display(recent_sales.sort_values(by='name').head(20))\n",
    "recent_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = join_sales_data(path, filename)\n",
    "data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "data.rename(columns={\n",
    "    'tradename': 'name', \n",
    "    'dateissued': 'date_issued',\n",
    "    'dayphone': 'phone',\n",
    "    'street_address': 'address1'\n",
    "}, inplace=True)\n",
    "\n",
    "data['zip_code'] = data['zipcode'].astype(str).str[:5]\n",
    "data['phone'] = data['phone'].astype(str).str[:-2]\n",
    "data['name'] = data['name'].str.strip().str.lower()\n",
    "\n",
    "data['reporting_period'] += '-01'\n",
    "date_cols = ['reporting_period', 'date_issued']\n",
    "for col in date_cols:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce', yearfirst=True,\n",
    "                               infer_datetime_format=True)\n",
    "\n",
    "# Only working with most recent reporting period for now. Will have to\n",
    "# refactor this portion if past observations are integrated into the model\n",
    "recent = data['reporting_period'] == data['reporting_period'].max()\n",
    "data = data[recent]\n",
    "\n",
    "data.dropna(subset=['name'], inplace=True)\n",
    "\n",
    "# Drop old columns we don't want anymore\n",
    "cols = ['ubi', 'suite/rm', 'zipcode']\n",
    "data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from \n",
    "    data/processed, calculates descriptive statistics for the population,\n",
    "    and plots charts that visualize interesting relationships between \n",
    "    features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed')\n",
    "    # describe_features(data, 'reports/')\n",
    "    # generate_charts(data, 'reports/figures/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you learn? What relationships do you think will be most helpful as you build your model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "*Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from \n",
    "    data/processed, calculates descriptive statistics for the population,\n",
    "    and plots charts that visualize interesting relationships between \n",
    "    features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed/')\n",
    "    # train, test = train_test_split(data)\n",
    "    # save_train_test(train, test, 'data/processed/')\n",
    "    # model = build_model()\n",
    "    # model.fit(train)\n",
    "    # save_model(model, 'models/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from \n",
    "    data/processed, calculates descriptive statistics for the population,\n",
    "    and plots charts that visualize interesting relationships between\n",
    "    features.\n",
    "    \"\"\"\n",
    "    # test_X, test_y = load_test_data('data/processed')\n",
    "    # trained_model = load_model('models/')\n",
    "    # predictions = trained_model.predict(test_X)\n",
    "    # metrics = evaluate(test_y, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project2)",
   "language": "python",
   "name": "project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
